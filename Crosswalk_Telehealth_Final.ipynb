{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crosswalk Telehealth - Final\n",
    "\n",
    "Targeted search for **03.03CV - Telehealth consultation**\n",
    "\n",
    "Fixes:\n",
    "- Level_2 detection improved (no sentence fragments)\n",
    "- Skips Appendix J (lookup table, not service definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pandas pdfplumber openpyxl tqdm -q\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Select ALL 3 files (Ctrl+click):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "ALBERTA_FILE = ONTARIO_PDF = ONTARIO_FEES = None\n",
    "for f in uploaded.keys():\n",
    "    if f.endswith('.xlsx'): ALBERTA_FILE = f\n",
    "    elif f.endswith('.pdf'): ONTARIO_PDF = f\n",
    "    elif '001' in f: ONTARIO_FEES = f\n",
    "\n",
    "print(f\"\\nAlberta: {ALBERTA_FILE}\")\n",
    "print(f\"PDF: {ONTARIO_PDF}\")\n",
    "print(f\"Fees: {ONTARIO_FEES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"  # <-- Paste your key\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    from getpass import getpass\n",
    "    OPENAI_API_KEY = getpass(\"API Key: \")\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "print(\"API ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data with Improved Section Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import json\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Ontario fees\n",
    "on_fees = {}\n",
    "with open(ONTARIO_FEES, 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line) >= 30 and line[12:20] == '99999999':\n",
    "            code = line[0:4].strip()\n",
    "            try: on_fees[code] = int(line[20:30]) / 1000\n",
    "            except: pass\n",
    "print(f\"Ontario fee codes: {len(on_fees)}\")\n",
    "\n",
    "# Load PDF with improved section detection\n",
    "print(\"\\nLoading PDF and detecting sections...\")\n",
    "pdf_pages = {}\n",
    "page_sections = {}  # page_num -> {\"level1\": \"...\", \"level2\": \"...\"}\n",
    "appendix_pages = set()  # Track appendix pages to skip\n",
    "\n",
    "current_level1 = \"UNKNOWN SECTION\"\n",
    "current_level2 = \"\"\n",
    "in_appendix = False\n",
    "\n",
    "def is_valid_level2_header(line):\n",
    "    \"\"\"Check if line is a valid Level 2 subsection header.\"\"\"\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Must start with capital letter followed by lowercase\n",
    "    if not re.match(r'^[A-Z][a-z]', line):\n",
    "        return False\n",
    "    \n",
    "    # Reasonable length for a header\n",
    "    if len(line) < 5 or len(line) > 60:\n",
    "        return False\n",
    "    \n",
    "    # Reject if contains sentence-ending punctuation mid-string or at end\n",
    "    if re.search(r'[.!?]\\s*$', line):  # Ends with period/punctuation\n",
    "        return False\n",
    "    if re.search(r'[.!?]\\s+[A-Z]', line):  # Has sentence break\n",
    "        return False\n",
    "    \n",
    "    # Reject if contains brackets that suggest it's a note/reference\n",
    "    if re.search(r'[\\[\\]\\(\\)]', line):\n",
    "        return False\n",
    "    \n",
    "    # Reject if starts with common non-header words\n",
    "    non_header_starts = ['The ', 'This ', 'A ', 'An ', 'If ', 'For ', 'When ', 'Where ', \n",
    "                         'Note', 'See ', 'Refer', 'Include', 'Exclude', 'Payment']\n",
    "    for start in non_header_starts:\n",
    "        if line.startswith(start):\n",
    "            return False\n",
    "    \n",
    "    # Reject if has digits in first few chars (likely a code)\n",
    "    if any(c.isdigit() for c in line[:4]):\n",
    "        return False\n",
    "    \n",
    "    # Reject if contains dots pattern (table of contents)\n",
    "    if '....' in line or '. . .' in line:\n",
    "        return False\n",
    "    \n",
    "    # Looks like a valid header\n",
    "    return True\n",
    "\n",
    "with pdfplumber.open(ONTARIO_PDF) as pdf:\n",
    "    for i, page in enumerate(tqdm(pdf.pages)):\n",
    "        page_num = i + 1\n",
    "        try:\n",
    "            text = page.extract_text()\n",
    "            if not text:\n",
    "                continue\n",
    "            \n",
    "            # Check if we're entering an Appendix\n",
    "            if 'APPENDIX' in text.upper()[:500]:\n",
    "                # Check for Appendix header\n",
    "                if re.search(r'APPENDIX\\s+[A-Z]', text.upper()[:500]):\n",
    "                    in_appendix = True\n",
    "            \n",
    "            # Mark appendix pages\n",
    "            if in_appendix:\n",
    "                appendix_pages.add(page_num)\n",
    "            \n",
    "            pdf_pages[page_num] = text\n",
    "            \n",
    "            # Detect section headers from first 10 lines only\n",
    "            lines = text.split('\\n')[:10]\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Level 1: ALL CAPS headers (like \"CONSULTATIONS AND VISITS\")\n",
    "                if len(line) > 10 and line.isupper():\n",
    "                    # Must not start with digits\n",
    "                    if not any(c.isdigit() for c in line[:4]):\n",
    "                        # Must not be PAGE X or contain dots\n",
    "                        if not line.startswith('PAGE') and '....' not in line:\n",
    "                            # Check it's not APPENDIX (we handle that separately)\n",
    "                            if not line.startswith('APPENDIX'):\n",
    "                                current_level1 = line\n",
    "                                current_level2 = \"\"  # Reset level 2\n",
    "                \n",
    "                # Level 2: Title case subsection headers\n",
    "                elif is_valid_level2_header(line):\n",
    "                    current_level2 = line\n",
    "            \n",
    "            page_sections[page_num] = {\n",
    "                \"level1\": current_level1,\n",
    "                \"level2\": current_level2\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Page {page_num} error: {e}\")\n",
    "\n",
    "print(f\"PDF pages: {len(pdf_pages)}\")\n",
    "print(f\"Appendix pages (will skip): {len(appendix_pages)}\")\n",
    "print(f\"\\nSample sections detected:\")\n",
    "for pg in [30, 50, 75, 100, 150, 200]:\n",
    "    if pg in page_sections and pg not in appendix_pages:\n",
    "        s = page_sections[pg]\n",
    "        l2 = s['level2'][:30] if s['level2'] else '(none)'\n",
    "        print(f\"  Page {pg}: {s['level1'][:35]} > {l2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alberta Code Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full clinical definition from Alberta Schedule\n",
    "AB_CODE = \"03.03CV\"\n",
    "AB_DESC = \"Telehealth consultation\"\n",
    "AB_FEE = 25.09\n",
    "\n",
    "AB_CLINICAL_DEFINITION = \"\"\"Assessment of a patient's condition via telephone or secure videoconference.\n",
    "\n",
    "NOTE:\n",
    "- At minimum: limited assessment requiring history related to presenting problems, appropriate records review, and advice to the patient\n",
    "- Total physician time spent providing patient care must be MINIMUM 10 MINUTES\n",
    "- If less than 10 minutes same day, must use HSC 03.01AD instead\n",
    "- May only be claimed if service was initiated by the patient or their agent\n",
    "- May only be claimed if service is personally rendered by the physician\n",
    "- Benefit includes ordering appropriate diagnostic tests and discussion with patient\n",
    "- Patient record must include detailed summary of all services including start/stop times\n",
    "- Time spent on administrative tasks cannot be claimed\n",
    "- May NOT be claimed same day as: 03.01AD, 03.01S, 03.01T, 03.03FV, 03.05JR, 03.08CV, 08.19CV, 08.19CW, or 08.19CX by same physician for same patient\n",
    "- May NOT be claimed same day as in-person visit or consultation by same physician for same patient\n",
    "\n",
    "Category: V Visit (Virtual)\n",
    "Base rate: $25.09\"\"\"\n",
    "\n",
    "print(f\"Alberta Code: {AB_CODE}\")\n",
    "print(f\"Description: {AB_DESC}\")\n",
    "print(f\"Fee: ${AB_FEE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Targeted Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "PAGES_PER_CALL = 10\ntotal_cost = 0.0\n\ndef track_cost(inp, out):\n    global total_cost\n    total_cost += (inp/1e6)*3.0 + (out/1e6)*15.0\n\ndef get_section_for_pages(batch_pages):\n    \"\"\"Get level1/level2 section for a batch of pages.\"\"\"\n    for pg in batch_pages:\n        if pg in page_sections:\n            return page_sections[pg]\n    return {\"level1\": \"Unknown\", \"level2\": \"\"}\n\ndef build_prompt(ab_code, ab_desc, ab_fee, clinical_def, batch_pages, context, section_info):\n    section_text = section_info['level1']\n    if section_info['level2']:\n        section_text += f\" > {section_info['level2']}\"\n    \n    return f\"\"\"You are a senior physician billing specialist mapping Alberta fee codes to Ontario equivalents.\n\nALBERTA CODE TO MATCH:\n- Code: {ab_code}\n- Description: {ab_desc}\n- Fee: ${ab_fee}\n\nCLINICAL SERVICE DEFINITION:\n{clinical_def}\n\nThis is a BASIC PATIENT-FACING virtual visit by any physician (not specialist-specific, not physician-to-physician).\n\nONTARIO SCHEDULE EXCERPT (pages {batch_pages[0]}-{batch_pages[-1]}):\nCurrent Section: {section_text}\n\n{context}\n\nTASK:\nFind Ontario codes that bill for THIS SAME CLINICAL ENCOUNTER — a basic virtual care assessment between a physician and patient.\n\nSTEP 1 — FIND PRIMARY CODE(S):\nWhat Ontario code(s) would a physician bill for this same 10+ minute patient-facing virtual assessment?\n- Look for: Limited/basic virtual care visits, telephone assessments, video assessments\n- Separate codes if Ontario splits by modality (phone vs video)\n\nSTEP 2 — FIND ADD-ON CODES:\nWhat Ontario codes can be billed IN ADDITION TO the primary code for this type of visit?\n- Each add-on must link to specific primary code(s)\n- Only include add-ons specifically eligible for virtual care visits\n- IMPORTANT: If an add-on has DIFFERENT FEES by modality (telephone vs video), return it as SEPARATE entries\n\nDO NOT INCLUDE:\n- Physician-to-physician consultations (K730-K737) — wrong service type\n- E-assessments (K738-K741) — these are specialist-to-PCP, not patient-facing\n- Specialist consultations (A010, A913, A914) — wrong provider scope\n- Ambulance/transport/detention codes — completely different services\n- Diagnostic procedure codes (ECG, Holter, imaging) — not consultations\n- Psychiatry/psychology specific codes — different specialty\n- In-person visit codes (unless Ontario has no virtual equivalent)\n- Appendix reference codes (codes ending in A that are just claim submission references)\n\nJSON only:\n{{\n  \"found\": true/false,\n  \"primary_codes\": [\n    {{\n      \"code\": \"...\",\n      \"description\": \"full description from schedule\",\n      \"fee\": 00.00,\n      \"modality\": \"telephone|video|both\",\n      \"reasoning\": \"why this matches\"\n    }}\n  ],\n  \"add_on_codes\": [\n    {{\n      \"code\": \"...\",\n      \"description\": \"...\",\n      \"fee\": 00.00,\n      \"modality\": \"telephone|video|both\",\n      \"links_to\": [\"primary_code1\", \"primary_code2\"],\n      \"condition\": \"when this add-on applies\"\n    }}\n  ]\n}}\n\nIMPORTANT: If a code has different fees for telephone vs video, create SEPARATE entries for each modality with the specific fee.\n\nIf no relevant codes on these pages: {{\"found\": false, \"primary_codes\": [], \"add_on_codes\": []}}\"\"\"\n\ndef search_for_matches():\n    \"\"\"Search all pages for matching codes (skipping appendices).\"\"\"\n    \n    all_primary = []\n    all_addons = []\n    \n    # Filter out appendix pages\n    page_nums = sorted([p for p in pdf_pages.keys() if p not in appendix_pages])\n    batches = [page_nums[i:i+PAGES_PER_CALL] for i in range(0, len(page_nums), PAGES_PER_CALL)]\n    \n    print(f\"Searching {len(page_nums)} pages in {len(batches)} batches (skipped {len(appendix_pages)} appendix pages)...\\n\")\n    \n    for batch_pages in tqdm(batches, desc=\"Searching\"):\n        context = \"\\n\".join([f\"=== PAGE {p} ===\\n{pdf_pages[p]}\" for p in batch_pages if p in pdf_pages])\n        section_info = get_section_for_pages(batch_pages)\n        \n        prompt = build_prompt(AB_CODE, AB_DESC, AB_FEE, AB_CLINICAL_DEFINITION, batch_pages, context, section_info)\n        \n        try:\n            resp = client.chat.completions.create(\n                model=\"gpt-5.1-2025-11-13\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.1,\n                max_completion_tokens=1500\n            )\n            track_cost(resp.usage.prompt_tokens, resp.usage.completion_tokens)\n            \n            content = resp.choices[0].message.content\n            match = re.search(r'\\{[\\s\\S]*\\}', content)\n            if match:\n                result = json.loads(match.group())\n                \n                if result.get('found'):\n                    n_primary = len(result.get('primary_codes', []))\n                    n_addon = len(result.get('add_on_codes', []))\n                    print(f\"  Pages {batch_pages[0]}-{batch_pages[-1]}: {n_primary} primary, {n_addon} add-ons\")\n                    \n                    for p in result.get('primary_codes', []):\n                        p['pages'] = f\"{batch_pages[0]}-{batch_pages[-1]}\"\n                        p['level1'] = section_info['level1']\n                        p['level2'] = section_info['level2']\n                        all_primary.append(p)\n                    \n                    for a in result.get('add_on_codes', []):\n                        a['pages'] = f\"{batch_pages[0]}-{batch_pages[-1]}\"\n                        a['level1'] = section_info['level1']\n                        a['level2'] = section_info['level2']\n                        all_addons.append(a)\n                        \n        except Exception as e:\n            print(f\"Error on pages {batch_pages[0]}-{batch_pages[-1]}: {e}\")\n    \n    # Deduplicate by code+modality (to keep separate modality entries)\n    seen_primary = {}\n    for p in all_primary:\n        key = f\"{p.get('code', '')}_{p.get('modality', '')}\"\n        if key and key not in seen_primary:\n            seen_primary[key] = p\n    \n    seen_addon = {}\n    for a in all_addons:\n        key = f\"{a.get('code', '')}_{a.get('modality', '')}\"\n        if key and key not in seen_addon:\n            seen_addon[key] = a\n    \n    return list(seen_primary.values()), list(seen_addon.values())\n\nprint(\"Search function ready\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RUN SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(f\"SEARCHING FOR: {AB_CODE} - {AB_DESC}\")\nprint(\"=\"*70)\n\nprimary_codes, addon_codes = search_for_matches()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"RESULTS\")\nprint(\"=\"*70)\n\nprint(f\"\\n--- PRIMARY CODES ({len(primary_codes)}) ---\")\nprint(\"These are the Ontario codes for the same clinical service:\\n\")\nfor p in primary_codes:\n    fee = p.get('fee') if p.get('fee') else on_fees.get(p['code'], '?')\n    print(f\"{p['code']:6} | ${str(fee):>7} | {p.get('modality', '?'):10}\")\n    print(f\"         Section: {p.get('level1', '')[:30]} > {p.get('level2', '')[:25]}\")\n    print(f\"         {p.get('description', '')[:55]}\")\n    print()\n\nprint(f\"\\n--- ADD-ON CODES ({len(addon_codes)}) ---\")\nprint(\"These can be billed IN ADDITION to primary codes:\\n\")\nfor a in addon_codes:\n    fee = a.get('fee') if a.get('fee') else on_fees.get(a['code'], '?')\n    links = ', '.join(a.get('links_to', [])) if a.get('links_to') else 'unspecified'\n    modality = a.get('modality', 'both')\n    print(f\"{a['code']:6} | ${str(fee):>7} | {modality:10} | Links to: {links}\")\n    print(f\"         Section: {a.get('level1', '')[:30]} > {a.get('level2', '')[:25]}\")\n    print(f\"         {a.get('description', '')[:55]}\")\n    print(f\"         Condition: {a.get('condition', '')[:45]}\")\n    print()\n\nprint(\"=\"*70)\nprint(f\"Total cost: ${total_cost:.2f}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Build output with Level_1 and Level_2 columns\n# Fee comes from GPT response (handles modality-specific fees)\nresults = []\n\nfor p in primary_codes:\n    # Use fee from GPT if provided, else lookup\n    fee = p.get('fee') if p.get('fee') else on_fees.get(p.get('code', ''), '')\n    results.append({\n        'AB_Code': AB_CODE,\n        'AB_Description': AB_DESC,\n        'AB_Fee': AB_FEE,\n        'ON_Code': p.get('code', ''),\n        'ON_Description': p.get('description', ''),\n        'ON_Fee': fee,\n        'Type': 'PRIMARY',\n        'Modality': p.get('modality', ''),\n        'Links_To': '',\n        'Condition': '',\n        'Reasoning': p.get('reasoning', ''),\n        'Level_1_Section': p.get('level1', ''),\n        'Level_2_Subsection': p.get('level2', ''),\n        'Pages': p.get('pages', '')\n    })\n\nfor a in addon_codes:\n    # Use fee from GPT if provided, else lookup\n    fee = a.get('fee') if a.get('fee') else on_fees.get(a.get('code', ''), '')\n    results.append({\n        'AB_Code': AB_CODE,\n        'AB_Description': AB_DESC,\n        'AB_Fee': AB_FEE,\n        'ON_Code': a.get('code', ''),\n        'ON_Description': a.get('description', ''),\n        'ON_Fee': fee,\n        'Type': 'ADD-ON',\n        'Modality': a.get('modality', ''),\n        'Links_To': ', '.join(a.get('links_to', [])) if a.get('links_to') else '',\n        'Condition': a.get('condition', ''),\n        'Reasoning': '',\n        'Level_1_Section': a.get('level1', ''),\n        'Level_2_Subsection': a.get('level2', ''),\n        'Pages': a.get('pages', '')\n    })\n\ndf = pd.DataFrame(results)\ndf.to_excel('crosswalk_telehealth_final.xlsx', index=False)\nprint(f\"Saved {len(results)} results to crosswalk_telehealth_final.xlsx\")\n\nfrom google.colab import files\nfiles.download('crosswalk_telehealth_final.xlsx')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}