{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontario Section Pilot - Crosswalk by Level 2 Sections\n",
    "\n",
    "**Approach:** Process PDF by Level 2 sections (from reference CSV) for coherent extraction.\n",
    "\n",
    "**Ontario-Specific Features:**\n",
    "- **H/P Columns**: Hospital vs Professional/Office setting → separate rows\n",
    "- **Surgical Columns**: Surg/Asst/Anae fees → separate rows per fee type\n",
    "- **Level 3**: Extracted by LLM (e.g., \"INCISION\", \"EXCISION\")\n",
    "\n",
    "**Output Columns:**\n",
    "- `Setting`: Hospital, Professional, N/A\n",
    "- `Fee_Type`: Surgeon, Assistant, Anaesthesia, Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pandas pdfplumber openpyxl tqdm PyMuPDF -q\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Upload Ontario PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Upload Ontario Schedule of Benefits PDF:\")\n",
    "print(\"(ON - February 20, 2024 (effective April 1, 2024).pdf)\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "ON_PDF = None\n",
    "for f in uploaded.keys():\n",
    "    ON_PDF = f\n",
    "    break\n",
    "\n",
    "if ON_PDF:\n",
    "    print(f\"\\nLoaded: {ON_PDF}\")\n",
    "else:\n",
    "    print(\"ERROR: No file uploaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Upload Section Reference CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload on_section_reference_full.csv:\")\n",
    "uploaded_ref = files.upload()\n",
    "\n",
    "section_ref_file = list(uploaded_ref.keys())[0]\n",
    "df_section_ref = pd.read_csv(section_ref_file)\n",
    "\n",
    "# Sort by page_start\n",
    "df_section_ref = df_section_ref.sort_values('page_start').reset_index(drop=True)\n",
    "\n",
    "# Fill empty level_2 with level_1 value\n",
    "df_section_ref['level_2'] = df_section_ref['level_2'].fillna('')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_section_ref)} section entries\")\n",
    "print(f\"Unique Level 1 sections: {df_section_ref['level_1'].nunique()}\")\n",
    "print(f\"\\nLevel 1 sections:\")\n",
    "for l1 in df_section_ref['level_1'].unique():\n",
    "    count = len(df_section_ref[df_section_ref['level_1'] == l1])\n",
    "    print(f\"  {l1}: {count} subsections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"  # <-- Paste your key here\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    from getpass import getpass\n",
    "    OPENAI_API_KEY = getpass(\"API Key: \")\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "print(\"API ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Split PDF into Level 2 Section Chunks\n",
    "\n",
    "Extract text for each Level 2 section based on page ranges from CSV.\n",
    "Skip General Preamble (pages 1-126) and Appendices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"Loading PDF and splitting into Level 2 sections...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# First, load all pages\n",
    "pdf_pages = {}\n",
    "with pdfplumber.open(ON_PDF) as pdf:\n",
    "    total_pages = len(pdf.pages)\n",
    "    for i, page in enumerate(tqdm(pdf.pages, desc=\"Loading pages\")):\n",
    "        page_num = i + 1\n",
    "        try:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                pdf_pages[page_num] = text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f\"\\nLoaded {len(pdf_pages)} pages from PDF (total: {total_pages})\")\n",
    "\n",
    "# Sections to skip\n",
    "SKIP_LEVEL1 = [\n",
    "    \"General Preamble\",\n",
    "    \"Appendix A\",\n",
    "    \"Appendix B\",\n",
    "    \"Appendix C\",\n",
    "    \"Appendix D\",\n",
    "    \"Appendix F\",\n",
    "    \"Appendix G\",\n",
    "    \"Appendix H\",\n",
    "    \"Appendix J\",\n",
    "    \"Appendix Q\",\n",
    "    \"Numeric Index\",\n",
    "]\n",
    "\n",
    "# Build section chunks using Level 2 page ranges\n",
    "section_chunks = {}\n",
    "\n",
    "for idx, row in df_section_ref.iterrows():\n",
    "    level_1 = row['level_1']\n",
    "    level_2 = row['level_2'] if row['level_2'] else level_1\n",
    "    start_page = int(row['page_start'])\n",
    "    \n",
    "    # Skip preamble and appendices\n",
    "    if level_1 in SKIP_LEVEL1:\n",
    "        continue\n",
    "    \n",
    "    # Create unique section key\n",
    "    section_key = f\"{level_1} | {level_2}\" if level_2 != level_1 else level_1\n",
    "    \n",
    "    # End page is start of next section - 1, or last page of PDF\n",
    "    if idx + 1 < len(df_section_ref):\n",
    "        end_page = int(df_section_ref.iloc[idx + 1]['page_start']) - 1\n",
    "    else:\n",
    "        end_page = total_pages\n",
    "    \n",
    "    # Extract text for this section\n",
    "    section_text = \"\"\n",
    "    pages_in_section = []\n",
    "    for pg in range(start_page, end_page + 1):\n",
    "        if pg in pdf_pages:\n",
    "            section_text += f\"\\n=== PAGE {pg} ===\\n{pdf_pages[pg]}\"\n",
    "            pages_in_section.append(pg)\n",
    "    \n",
    "    section_chunks[section_key] = {\n",
    "        'text': section_text,\n",
    "        'level_1': level_1,\n",
    "        'level_2': level_2,\n",
    "        'start_page': start_page,\n",
    "        'end_page': end_page,\n",
    "        'page_count': len(pages_in_section),\n",
    "        'char_count': len(section_text)\n",
    "    }\n",
    "\n",
    "print(f\"\\nCreated {len(section_chunks)} section chunks (after skipping preamble/appendices):\")\n",
    "print(\"-\"*70)\n",
    "for name, info in section_chunks.items():\n",
    "    print(f\"  {name[:55]:55} | Pages {info['start_page']:3}-{info['end_page']:3} ({info['page_count']:2} pgs) | {info['char_count']:,} chars\")\n",
    "\n",
    "print(\"\\nSection chunks ready for processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Alberta Code Definition + Prompt Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Alberta code definition\n",
    "AB_CODE = \"03.03CV\"\n",
    "AB_DESC = \"Telehealth consultation\"\n",
    "AB_FEE = 25.09\n",
    "\n",
    "AB_CLINICAL_DEFINITION = \"\"\"Assessment of a patient's condition via telephone or secure videoconference.\n",
    "\n",
    "NOTE:\n",
    "- At minimum: limited assessment requiring history related to presenting problems, appropriate records review, and advice to the patient\n",
    "- Total physician time spent providing patient care must be MINIMUM 10 MINUTES\n",
    "- If less than 10 minutes same day, must use HSC 03.01AD instead\n",
    "- May only be claimed if service was initiated by the patient or their agent\n",
    "- May only be claimed if service is personally rendered by the physician\n",
    "- Benefit includes ordering appropriate diagnostic tests and discussion with patient\n",
    "- Patient record must include detailed summary of all services including start/stop times\n",
    "- Time spent on administrative tasks cannot be claimed\n",
    "- May NOT be claimed same day as: 03.01AD, 03.01S, 03.01T, 03.03FV, 03.05JR, 03.08CV, 08.19CV, 08.19CW, or 08.19CX by same physician for same patient\n",
    "- May NOT be claimed same day as in-person visit or consultation by same physician for same patient\n",
    "\n",
    "Category: V Visit (Virtual)\n",
    "Base rate: $25.09\"\"\"\n",
    "\n",
    "# Tracking\n",
    "total_cost = 0.0\n",
    "total_calls = 0\n",
    "\n",
    "def track_cost(inp, out):\n",
    "    global total_cost, total_calls\n",
    "    total_cost += (inp/1e6)*3.0 + (out/1e6)*15.0\n",
    "    total_calls += 1\n",
    "\n",
    "def build_section_prompt(section_key, section_info):\n",
    "    \"\"\"Build prompt for processing a complete Level 2 section.\"\"\"\n",
    "    level_1 = section_info['level_1']\n",
    "    level_2 = section_info['level_2']\n",
    "    section_text = section_info['text']\n",
    "    start_page = section_info['start_page']\n",
    "    end_page = section_info['end_page']\n",
    "    \n",
    "    return f\"\"\"You are a senior physician billing specialist mapping Alberta fee codes to Ontario equivalents.\n",
    "\n",
    "ALBERTA CODE TO MATCH:\n",
    "- Code: {AB_CODE}\n",
    "- Description: {AB_DESC}\n",
    "- Fee: ${AB_FEE}\n",
    "\n",
    "CLINICAL SERVICE DEFINITION:\n",
    "{AB_CLINICAL_DEFINITION}\n",
    "\n",
    "This is a BASIC PATIENT-FACING virtual visit by any physician (not specialist-specific, not physician-to-physician).\n",
    "\n",
    "You are reviewing the section: {level_1} > {level_2}\n",
    "Pages {start_page} to {end_page}\n",
    "\n",
    "ONTARIO SCHEDULE OF BENEFITS - SECTION:\n",
    "\n",
    "{section_text}\n",
    "\n",
    "TASK:\n",
    "Find ALL Ontario codes in this section that bill for patient-facing virtual assessments (telephone or video consultations with patients).\n",
    "\n",
    "ONTARIO-SPECIFIC EXTRACTION RULES:\n",
    "\n",
    "1. **H/P COLUMNS (Setting)**:\n",
    "   - If a code has BOTH H (Hospital) and P (Professional/Office) fees, create SEPARATE entries for each\n",
    "   - H = Hospital setting, P = Professional/Office setting\n",
    "   - If only one fee exists, use that setting\n",
    "\n",
    "2. **SURGICAL FEE COLUMNS**:\n",
    "   - Surg = Surgeon fee → create entry with fee_type \"Surgeon\"\n",
    "   - Asst = Assistant fee → create entry with fee_type \"Assistant\" (skip if \"nil\")\n",
    "   - Anae = Anaesthesia units → create entry with fee_type \"Anaesthesia\" (these are TIME UNITS, not dollars)\n",
    "\n",
    "3. **CODE PREFIXES** (indicate service type, NOT setting):\n",
    "   - A = Assessments/consultations\n",
    "   - E = Diagnostic/therapeutic procedures\n",
    "   - G = General listings\n",
    "   - K = Special visit premiums\n",
    "   - Z = Surgical procedures\n",
    "\n",
    "ACCURACY RULES:\n",
    "\n",
    "1. **ONLY REAL CODES**: Return ONLY codes that LITERALLY appear in the text above.\n",
    "   - Copy the EXACT code as shown (e.g., A003, K017, Z101)\n",
    "   - NEVER invent, fabricate, or guess codes\n",
    "\n",
    "2. **EXACT VALUES**: Copy fee EXACTLY as shown in the document\n",
    "   - Use exact decimal values (e.g., \"87.35\" not \"87.00\")\n",
    "   - For Anae column, these are UNITS not dollars\n",
    "\n",
    "3. **FULL DESCRIPTIONS - CLIENT READY FORMAT**:\n",
    "   - Copy the COMPLETE service description as written in the schedule\n",
    "   - Do NOT abbreviate or truncate\n",
    "   - Use sentence case for consistency\n",
    "   - Include qualifying details (e.g., \"minimum 50 minutes\")\n",
    "\n",
    "4. **LEVEL 3 EXTRACTION**:\n",
    "   - Extract the subsection heading the code appears under (e.g., \"INCISION\", \"EXCISION\", \"GENERAL LISTINGS\")\n",
    "   - This becomes level_3_heading\n",
    "\n",
    "5. **MODALITY**: Only include modalities explicitly stated\n",
    "   - \"telephone\" = text says telephone/phone\n",
    "   - \"video\" = text says video/videoconference\n",
    "   - \"both\" = text explicitly allows BOTH, or doesn't restrict\n",
    "\n",
    "WHAT TO LOOK FOR:\n",
    "- Virtual care services\n",
    "- Telehealth consultations\n",
    "- Telephone assessments/consultations\n",
    "- Video assessments/consultations\n",
    "- Any code that can be billed for a patient-facing virtual encounter\n",
    "\n",
    "DO NOT INCLUDE:\n",
    "- Physician-to-physician consultations (e-consults between doctors)\n",
    "- In-person only codes\n",
    "- Diagnostic procedures (ECG, imaging, labs)\n",
    "- Codes you cannot find literally in the text\n",
    "\n",
    "JSON only:\n",
    "{{\n",
    "  \"section_key\": \"{section_key}\",\n",
    "  \"found\": true/false,\n",
    "  \"codes\": [\n",
    "    {{\n",
    "      \"code\": \"EXACT code (e.g., A003, K017)\",\n",
    "      \"description\": \"COMPLETE description in sentence case\",\n",
    "      \"fee\": \"EXACT fee value or units\",\n",
    "      \"fee_type\": \"Standard|Surgeon|Assistant|Anaesthesia\",\n",
    "      \"setting\": \"Hospital|Professional|N/A\",\n",
    "      \"modality\": \"telephone|video|both\",\n",
    "      \"page_found\": <integer>,\n",
    "      \"level_3_heading\": \"subsection heading (e.g., GENERAL LISTINGS, INCISION)\",\n",
    "      \"is_addon\": true/false,\n",
    "      \"links_to\": [\"codes this links to\"] or [],\n",
    "      \"condition\": \"conditions/notes if any\",\n",
    "      \"reasoning\": \"brief explanation why this matches\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "IMPORTANT: For codes with multiple fee types (Surg/Asst/Anae) or settings (H/P), create SEPARATE entries for each combination.\n",
    "\n",
    "If no telehealth/virtual codes in this section: {{\"section_key\": \"{section_key}\", \"found\": false, \"codes\": []}}\"\"\"\n",
    "\n",
    "print(f\"Alberta Code: {AB_CODE} - {AB_DESC} (${AB_FEE})\")\n",
    "print(\"Prompt builder ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Phase 1 - Process Each Level 2 Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Process each Level 2 section\n",
    "\n",
    "prov_code = \"ON\"\n",
    "prov_name = \"Ontario\"\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"PHASE 1: PROCESSING BY LEVEL 2 SECTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "all_results = []\n",
    "code_chunks = {}  # Store section text for Phase 2\n",
    "\n",
    "def get_dynamic_max_tokens(char_count):\n",
    "    \"\"\"Set max_completion_tokens based on section size.\"\"\"\n",
    "    if char_count > 150000:\n",
    "        return 20000\n",
    "    elif char_count > 80000:\n",
    "        return 14000\n",
    "    elif char_count > 40000:\n",
    "        return 10000\n",
    "    elif char_count > 15000:\n",
    "        return 6000\n",
    "    else:\n",
    "        return 4000\n",
    "\n",
    "for section_key, section_info in tqdm(section_chunks.items(), desc=\"Processing sections\"):\n",
    "    \n",
    "    char_count = section_info['char_count']\n",
    "    max_tokens = get_dynamic_max_tokens(char_count)\n",
    "    \n",
    "    print(f\"\\n[{section_key[:60]}]\")\n",
    "    print(f\"  Pages {section_info['start_page']}-{section_info['end_page']} | {char_count:,} chars | {max_tokens} max tokens\")\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = build_section_prompt(section_key, section_info)\n",
    "    \n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-5.1-2025-11-13\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            max_completion_tokens=max_tokens\n",
    "        )\n",
    "        track_cost(resp.usage.prompt_tokens, resp.usage.completion_tokens)\n",
    "        \n",
    "        content = resp.choices[0].message.content\n",
    "        match = re.search(r'\\{[\\s\\S]*\\}', content)\n",
    "        \n",
    "        if match:\n",
    "            result = json.loads(match.group())\n",
    "            \n",
    "            codes_found = result.get('codes', [])\n",
    "            \n",
    "            if result.get('found') and codes_found:\n",
    "                print(f\"  -> Found {len(codes_found)} code entries\")\n",
    "                \n",
    "                for c in codes_found:\n",
    "                    code = c.get('code', '')\n",
    "                    fee = str(c.get('fee', ''))\n",
    "                    fee_type = c.get('fee_type', 'Standard')\n",
    "                    setting = c.get('setting', 'N/A')\n",
    "                    modality = c.get('modality', '')\n",
    "                    \n",
    "                    # Unique key for dedup and Phase 2\n",
    "                    unique_key = f\"{code}_{fee}_{fee_type}_{setting}_{section_key}\"\n",
    "                    code_chunks[unique_key] = section_info['text']\n",
    "                    \n",
    "                    all_results.append({\n",
    "                        'AB_Code': AB_CODE,\n",
    "                        'AB_Description': AB_DESC,\n",
    "                        'AB_Fee': AB_FEE,\n",
    "                        'Target_Province': prov_code,\n",
    "                        'Code': code,\n",
    "                        'Description': c.get('description', ''),\n",
    "                        'Fee': c.get('fee', ''),\n",
    "                        'Fee_Type': fee_type,\n",
    "                        'Setting': setting,\n",
    "                        'Type': 'ADD-ON' if c.get('is_addon') else 'PRIMARY',\n",
    "                        'Modality': modality,\n",
    "                        'Links_To': ', '.join(c.get('links_to', [])) if c.get('links_to') else '',\n",
    "                        'Condition': c.get('condition', ''),\n",
    "                        'Reasoning': c.get('reasoning', ''),\n",
    "                        'Level_1_Section': section_info['level_1'],\n",
    "                        'Level_2_Subsection': section_info['level_2'],\n",
    "                        'Level_3_Heading': c.get('level_3_heading', ''),\n",
    "                        'Page_Found': c.get('page_found', ''),\n",
    "                        '_unique_key': unique_key\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"  -> No telehealth codes found\")\n",
    "        else:\n",
    "            print(f\"  -> ERROR: Could not parse JSON response\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERROR: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"PHASE 1 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total code entries found: {len(all_results)}\")\n",
    "print(f\"  - PRIMARY: {sum(1 for r in all_results if r['Type'] == 'PRIMARY')}\")\n",
    "print(f\"  - ADD-ON: {sum(1 for r in all_results if r['Type'] == 'ADD-ON')}\")\n",
    "print(f\"\\nBy Fee Type:\")\n",
    "for ft in ['Standard', 'Surgeon', 'Assistant', 'Anaesthesia']:\n",
    "    count = sum(1 for r in all_results if r['Fee_Type'] == ft)\n",
    "    if count > 0:\n",
    "        print(f\"  - {ft}: {count}\")\n",
    "print(f\"\\nBy Setting:\")\n",
    "for s in ['Hospital', 'Professional', 'N/A']:\n",
    "    count = sum(1 for r in all_results if r['Setting'] == s)\n",
    "    if count > 0:\n",
    "        print(f\"  - {s}: {count}\")\n",
    "print(f\"\\nAPI calls: {total_calls} | Cost: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Phase 1 Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Phase 1 results by section\n",
    "import pandas as pd\n",
    "\n",
    "df_phase1 = pd.DataFrame(all_results)\n",
    "\n",
    "if len(df_phase1) > 0:\n",
    "    print(\"PHASE 1 RESULTS BY SECTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    section_counts = df_phase1.groupby('Level_1_Section').size().sort_index()\n",
    "    for section, count in section_counts.items():\n",
    "        print(f\"  {section[:50]:50} | {count:3} codes\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ALL CODES FOUND:\")\n",
    "    print(\"-\"*70)\n",
    "    for _, row in df_phase1.iterrows():\n",
    "        print(f\"  {row['Code']:8} | ${str(row['Fee']):>8} | {row['Fee_Type']:12} | {row['Setting']:12} | {row['Modality']:10} | pg {row['Page_Found']:>3}\")\n",
    "else:\n",
    "    print(\"No codes found in Phase 1\")\n",
    "\n",
    "# Save Phase 1\n",
    "phase1_file = 'phase1_on_section_pilot.xlsx'\n",
    "df_phase1.to_excel(phase1_file, index=False)\n",
    "print(f\"\\nSaved: {phase1_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 2: Attribute Extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Extract Rules of Application (General Preamble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Extract General Preamble/Rules pages for Ontario (pages 1-126)\n",
    "RULES_START_PAGE = 1\n",
    "RULES_END_PAGE = 126\n",
    "\n",
    "print(f\"Extracting General Preamble/Rules (pages {RULES_START_PAGE}-{RULES_END_PAGE})...\")\n",
    "\n",
    "# Open source PDF\n",
    "src_pdf = fitz.open(ON_PDF)\n",
    "\n",
    "# Create new PDF with preamble pages\n",
    "rules_pdf = fitz.open()\n",
    "rules_pdf.insert_pdf(src_pdf, from_page=RULES_START_PAGE-1, to_page=RULES_END_PAGE-1)\n",
    "\n",
    "# Save Rules PDF\n",
    "rules_pdf_file = 'on_general_preamble.pdf'\n",
    "rules_pdf.save(rules_pdf_file)\n",
    "print(f\"Saved: {rules_pdf_file} ({RULES_END_PAGE - RULES_START_PAGE + 1} pages)\")\n",
    "\n",
    "# Extract text from Rules for use in prompts\n",
    "rules_of_application_text = \"\"\n",
    "for page_num in range(RULES_START_PAGE - 1, RULES_END_PAGE):\n",
    "    page = src_pdf[page_num]\n",
    "    text = page.get_text()\n",
    "    if text:\n",
    "        rules_of_application_text += f\"\\n=== RULES PAGE {page_num + 1} ===\\n{text}\"\n",
    "\n",
    "src_pdf.close()\n",
    "rules_pdf.close()\n",
    "\n",
    "print(f\"Loaded General Preamble text: {len(rules_of_application_text):,} characters\")\n",
    "\n",
    "# Download the Rules PDF\n",
    "files.download(rules_pdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Load Extraction Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extraction taxonomy\n",
    "print(\"Upload extraction_taxonomy.xlsx:\")\n",
    "uploaded_tax = files.upload()\n",
    "\n",
    "taxonomy_file = list(uploaded_tax.keys())[0]\n",
    "df_taxonomy = pd.read_excel(taxonomy_file)\n",
    "\n",
    "print(f\"\\nLoaded {len(df_taxonomy)} attributes:\")\n",
    "for _, row in df_taxonomy.iterrows():\n",
    "    print(f\"  - {row['attribute']}: {row['data_type']}\")\n",
    "\n",
    "# Build taxonomy reference string for prompts\n",
    "taxonomy_reference = \"\\n\".join([\n",
    "    f\"- {row['attribute']} ({row['data_type']}): {row['definition']} Taxonomy: {row['taxonomy']}\"\n",
    "    for _, row in df_taxonomy.iterrows()\n",
    "])\n",
    "\n",
    "print(\"\\nTaxonomy loaded and ready for Phase 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Phase 2 - Extract Attributes for Each Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Extract attributes for each code using stored section chunks + rules\n",
    "\n",
    "def build_attribute_prompt(code_info, chunk_text, rules_text, taxonomy_ref):\n",
    "    \"\"\"Build prompt to extract attributes for a single code.\"\"\"\n",
    "    return f\"\"\"You are a senior physician billing specialist extracting detailed attributes for an Ontario billing code.\n",
    "\n",
    "CODE TO ANALYZE:\n",
    "- Code: {code_info['Code']}\n",
    "- Description: {code_info['Description']}\n",
    "- Fee: {code_info['Fee']}\n",
    "- Fee Type: {code_info['Fee_Type']}\n",
    "- Setting: {code_info['Setting']}\n",
    "- Type: {code_info['Type']}\n",
    "- Section: {code_info.get('Level_1_Section', 'N/A')} > {code_info.get('Level_2_Subsection', 'N/A')}\n",
    "- Condition (from Phase 1): {code_info.get('Condition', 'N/A')}\n",
    "\n",
    "ATTRIBUTES TO EXTRACT:\n",
    "{taxonomy_ref}\n",
    "\n",
    "GENERAL PREAMBLE/RULES:\n",
    "{rules_text[:50000]}\n",
    "\n",
    "CODE-SPECIFIC SECTION:\n",
    "{chunk_text[:30000]}\n",
    "\n",
    "TASK:\n",
    "Using ALL available information above, extract values for each attribute.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Use information from BOTH the General Preamble AND the code-specific section\n",
    "2. For each attribute, extract the value if found, or null if not stated\n",
    "3. For same_day_exclusions: return as array of code strings\n",
    "4. For additional_notes: ONLY include important billing information not captured elsewhere\n",
    "\n",
    "Return JSON only:\n",
    "{{\n",
    "  \"modality\": \"telephone|video|both|in_person|asynchronous|null\",\n",
    "  \"minimum_time_minutes\": integer or null,\n",
    "  \"frequency_per_day\": integer or null,\n",
    "  \"frequency_per_year\": integer or null,\n",
    "  \"frequency_per_year_period\": \"annual|quarterly|90_days|monthly|null\",\n",
    "  \"same_day_exclusions\": [\"code1\", \"code2\"] or [] or null,\n",
    "  \"premium_extended_hours\": \"rate% code conditions\" or null,\n",
    "  \"premium_location\": \"rate% code conditions\" or null,\n",
    "  \"premium_age\": \"rate% conditions\" or null,\n",
    "  \"premium_other\": \"rate% code conditions\" or null,\n",
    "  \"additional_notes\": \"other important billing info\" or null\n",
    "}}\"\"\"\n",
    "\n",
    "# Process each code\n",
    "phase2_results = []\n",
    "\n",
    "print(f\"Extracting attributes for {len(all_results)} codes...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for idx, code_info in enumerate(tqdm(all_results, desc=\"Extracting attributes\")):\n",
    "    unique_key = code_info.get('_unique_key', '')\n",
    "    chunk_text = code_chunks.get(unique_key, '')\n",
    "    \n",
    "    prompt = build_attribute_prompt(code_info, chunk_text, rules_of_application_text, taxonomy_reference)\n",
    "    \n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-5.1-2025-11-13\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            max_completion_tokens=1500\n",
    "        )\n",
    "        track_cost(resp.usage.prompt_tokens, resp.usage.completion_tokens)\n",
    "        \n",
    "        content = resp.choices[0].message.content\n",
    "        match = re.search(r'\\{[\\s\\S]*\\}', content)\n",
    "        \n",
    "        if match:\n",
    "            attrs = json.loads(match.group())\n",
    "            \n",
    "            # Convert same_day_exclusions array to string for Excel\n",
    "            if attrs.get('same_day_exclusions') and isinstance(attrs['same_day_exclusions'], list):\n",
    "                attrs['same_day_exclusions'] = ', '.join(attrs['same_day_exclusions'])\n",
    "            \n",
    "            phase2_results.append({\n",
    "                '_unique_key': unique_key,\n",
    "                **attrs\n",
    "            })\n",
    "            \n",
    "            n_filled = sum(1 for v in attrs.values() if v is not None and v != 'null' and v != '')\n",
    "            print(f\"  {code_info['Code']} ({code_info['Fee_Type']}, {code_info['Setting']}): {n_filled} attributes\")\n",
    "        else:\n",
    "            print(f\"  {code_info['Code']}: No JSON found\")\n",
    "            phase2_results.append({'_unique_key': unique_key})\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  {code_info['Code']}: Error - {e}\")\n",
    "        phase2_results.append({'_unique_key': unique_key})\n",
    "\n",
    "print(f\"\\nPhase 2 complete: {len(phase2_results)} codes processed\")\n",
    "print(f\"Total API cost: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Combine Phase 1 + Phase 2 and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Phase 1 and Phase 2 results\n",
    "\n",
    "df_phase1 = pd.DataFrame(all_results)\n",
    "df_phase2 = pd.DataFrame(phase2_results)\n",
    "\n",
    "# Merge on _unique_key\n",
    "df_combined = df_phase1.merge(df_phase2, on='_unique_key', how='left')\n",
    "\n",
    "# Drop internal column\n",
    "df_combined = df_combined.drop(columns=['_unique_key'])\n",
    "\n",
    "# Reorder columns\n",
    "column_order = [\n",
    "    'AB_Code', 'AB_Description', 'AB_Fee', 'Target_Province',\n",
    "    'Code', 'Description', 'Fee', 'Fee_Type', 'Setting', 'Type', 'Modality',\n",
    "    'Links_To', 'Condition', 'Reasoning',\n",
    "    'Level_1_Section', 'Level_2_Subsection', 'Level_3_Heading', 'Page_Found',\n",
    "    'modality', 'minimum_time_minutes', 'frequency_per_day', 'frequency_per_year',\n",
    "    'frequency_per_year_period', 'same_day_exclusions', 'premium_extended_hours',\n",
    "    'premium_location', 'premium_age', 'premium_other', 'additional_notes'\n",
    "]\n",
    "\n",
    "final_columns = [c for c in column_order if c in df_combined.columns]\n",
    "df_combined = df_combined[final_columns]\n",
    "\n",
    "print(f\"Combined DataFrame: {len(df_combined)} rows, {len(df_combined.columns)} columns\")\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Save Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL OUTPUT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "output_file = 'on_section_pilot_complete.xlsx'\n",
    "df_combined.to_excel(output_file, index=False)\n",
    "print(f\"\\nSaved: {output_file}\")\n",
    "print(f\"  - Rows: {len(df_combined)}\")\n",
    "print(f\"  - Columns: {len(df_combined.columns)}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n--- SUMMARY ---\")\n",
    "print(f\"Total code entries: {len(df_combined)}\")\n",
    "print(f\"  - PRIMARY: {len(df_combined[df_combined['Type'] == 'PRIMARY'])}\")\n",
    "print(f\"  - ADD-ON: {len(df_combined[df_combined['Type'] == 'ADD-ON'])}\")\n",
    "\n",
    "print(f\"\\n--- BY FEE TYPE ---\")\n",
    "fee_type_counts = df_combined['Fee_Type'].value_counts()\n",
    "for ft, count in fee_type_counts.items():\n",
    "    print(f\"  {ft}: {count}\")\n",
    "\n",
    "print(f\"\\n--- BY SETTING ---\")\n",
    "setting_counts = df_combined['Setting'].value_counts()\n",
    "for s, count in setting_counts.items():\n",
    "    print(f\"  {s}: {count}\")\n",
    "\n",
    "print(f\"\\n--- BY SECTION ---\")\n",
    "section_counts = df_combined.groupby('Level_1_Section').size().sort_index()\n",
    "for section, count in section_counts.items():\n",
    "    print(f\"  {section[:50]:50} | {count:3}\")\n",
    "\n",
    "print(f\"\\n--- COST ---\")\n",
    "print(f\"Total API calls: {total_calls}\")\n",
    "print(f\"Total cost: ${total_cost:.2f}\")\n",
    "\n",
    "# Download\n",
    "files.download(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
