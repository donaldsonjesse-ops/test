{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdGPCnixYKw9"
      },
      "source": [
        "# Provincial Billing Code Crosswalk Pipeline\n",
        "\n",
        "**Purpose:** Programmatically match Alberta physician billing codes to Ontario equivalents using:\n",
        "1. Semantic embedding similarity (sentence-transformers)\n",
        "2. Fee ratio validation\n",
        "3. Category/service type alignment\n",
        "4. Multi-signal confidence scoring\n",
        "\n",
        "**Author:** HelpSeeker Technologies  \n",
        "**Date:** 2025-01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9kbMoxAYKw_"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Upload 1/3: Alberta Excel file\")\n",
        "f1 = files.upload()\n",
        "\n",
        "print(\"\\nUpload 2/3: Ontario fee file (.001)\")\n",
        "f2 = files.upload()\n",
        "\n",
        "print(\"\\nUpload 3/3: Ontario PDF\")\n",
        "f3 = files.upload()\n",
        "\n",
        "print(\"\\n✓ All files uploaded!\")\n",
        "!ls -la *.xlsx *.pdf *001*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "-bYvLdABYobI",
        "outputId": "23d5bc05-d3dc-4d18-a573-98a4cb571e7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload 1/3: Alberta Excel file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f0fd592-35e8-4666-95c4-a1eb1cbe622f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1f0fd592-35e8-4666-95c4-a1eb1cbe622f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving merged_output_AB (2).xlsx to merged_output_AB (2).xlsx\n",
            "\n",
            "Upload 2/3: Ontario fee file (.001)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58a7fa58-a21b-45b2-8b0e-0b6b4be5135e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-58a7fa58-a21b-45b2-8b0e-0b6b4be5135e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving OCTSOB2025.001 to OCTSOB2025.001\n",
            "\n",
            "Upload 3/3: Ontario PDF\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5aa90e6e-dae0-48db-88bc-05a22a43aa41\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5aa90e6e-dae0-48db-88bc-05a22a43aa41\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving moh-schedule-benefit-2024-03-04.pdf to moh-schedule-benefit-2024-03-04.pdf\n",
            "\n",
            "✓ All files uploaded!\n",
            "-rw-r--r-- 1 root root  190769 Jan 19 22:33 'merged_output_AB (2).xlsx'\n",
            "-rw-r--r-- 1 root root  190769 Jan 19 22:31  merged_output_AB.xlsx\n",
            "-rw-r--r-- 1 root root 8426591 Jan 19 22:33  moh-schedule-benefit-2024-03-04.pdf\n",
            "-rw-r--r-- 1 root root  568029 Jan 19 22:33  OCTSOB2025.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2sQYaB7fYKw_"
      },
      "outputs": [],
      "source": [
        "# Install required packages (run once)\n",
        "!pip install sentence-transformers pandas openpyxl scikit-learn pdfplumber -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r16es7fOYKw_",
        "outputId": "a8318392-83a9-4e7d-a7e6-5bf8c3d5ba0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All packages loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pdfplumber\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All packages loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY_pOQTaYKxA"
      },
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uCCrXSaYKxA",
        "outputId": "51d71b19-22af-4bc7-d45f-4118f9fa841a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded:\n",
            "Config(alberta_file='merged_output_AB__2_.xlsx', ontario_fee_file='OCTSOB2025.001 2', ontario_pdf_file='moh-schedule-benefit-2024-03-04.pdf', embedding_model='all-MiniLM-L6-v2', min_similarity_threshold=0.4, high_confidence_threshold=0.75, fee_ratio_tolerance=0.5, output_file='AB_ON_Crosswalk_Validated.xlsx', top_k_matches=5)\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Configuration for the crosswalk pipeline\"\"\"\n",
        "\n",
        "    # File paths - UPDATE THESE FOR YOUR FILES\n",
        "    alberta_file: str = \"merged_output_AB__2_.xlsx\"\n",
        "    ontario_fee_file: str = \"OCTSOB2025.001 2\"  # Fixed-width fee data\n",
        "    ontario_pdf_file: str = \"moh-schedule-benefit-2024-03-04.pdf\"  # For descriptions\n",
        "\n",
        "    # Embedding model - medical domain works best\n",
        "    embedding_model: str = \"all-MiniLM-L6-v2\"  # Fast, good quality\n",
        "    # Alternative: \"pritamdeka/S-PubMedBert-MS-MARCO\" for medical domain\n",
        "\n",
        "    # Matching thresholds\n",
        "    min_similarity_threshold: float = 0.4  # Minimum cosine similarity to consider\n",
        "    high_confidence_threshold: float = 0.75  # Above this = high confidence match\n",
        "\n",
        "    # Fee validation\n",
        "    fee_ratio_tolerance: float = 0.5  # Allow 50% fee variance before flagging\n",
        "\n",
        "    # Output\n",
        "    output_file: str = \"AB_ON_Crosswalk_Validated.xlsx\"\n",
        "    top_k_matches: int = 5  # Number of candidate matches to return per code\n",
        "\n",
        "config = Config()\n",
        "print(f\"Configuration loaded:\\n{config}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbSeXzK1YKxA"
      },
      "source": [
        "## 3. Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iOdPkOsmYKxA"
      },
      "outputs": [],
      "source": [
        "def load_alberta_codes(filepath: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load Alberta billing codes from Excel file.\n",
        "    Returns deduplicated codes with descriptions and fees.\n",
        "    \"\"\"\n",
        "    df = pd.read_excel(filepath)\n",
        "\n",
        "    # Get unique codes with their core attributes\n",
        "    codes = df[['BILLING_CODE', 'DESCRIPTION', 'BASE_RATE', 'CATEGORY']].drop_duplicates(\n",
        "        subset=['BILLING_CODE']\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    codes.columns = ['code', 'description', 'fee', 'category']\n",
        "    codes['province'] = 'AB'\n",
        "\n",
        "    # Clean descriptions\n",
        "    codes['description_clean'] = codes['description'].str.lower().str.strip()\n",
        "\n",
        "    print(f\"✓ Loaded {len(codes)} Alberta codes\")\n",
        "    return codes\n",
        "\n",
        "\n",
        "def parse_ontario_fee_file(filepath: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Parse Ontario fixed-width fee schedule file.\n",
        "\n",
        "    File structure (75 chars per line):\n",
        "    - Chars 0-4: Fee code (4 chars)\n",
        "    - Chars 4-12: Start date YYYYMMDD\n",
        "    - Chars 12-20: End date YYYYMMDD (99999999 = active)\n",
        "    - Chars 20-30: Primary fee (in cents, divide by 100)\n",
        "    - Chars 30-40: Secondary field (H component for diagnostics)\n",
        "    - Chars 40-50: Tertiary field\n",
        "    - etc.\n",
        "    \"\"\"\n",
        "    records = []\n",
        "\n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if len(line) >= 30:\n",
        "                code = line[0:4]\n",
        "                start_date = line[4:12]\n",
        "                end_date = line[12:20]\n",
        "\n",
        "                # Primary fee field (divide by 1000 based on analysis)\n",
        "                try:\n",
        "                    fee_raw = int(line[20:30])\n",
        "                    fee = fee_raw / 1000  # Convert to dollars\n",
        "                except:\n",
        "                    fee = 0\n",
        "\n",
        "                # Technical component (H) for diagnostic codes\n",
        "                try:\n",
        "                    h_component = int(line[30:40]) / 1000 if len(line) >= 40 else 0\n",
        "                except:\n",
        "                    h_component = 0\n",
        "\n",
        "                records.append({\n",
        "                    'code': code,\n",
        "                    'start_date': start_date,\n",
        "                    'end_date': end_date,\n",
        "                    'fee': fee,\n",
        "                    'fee_h': h_component,\n",
        "                    'is_active': end_date == '99999999'\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "\n",
        "    # Filter to active codes only\n",
        "    active = df[df['is_active']].copy()\n",
        "\n",
        "    print(f\"✓ Parsed {len(active)} active Ontario codes from fee file\")\n",
        "    return active\n",
        "\n",
        "\n",
        "def extract_ontario_descriptions_from_pdf(filepath: str,\n",
        "                                          page_ranges: List[Tuple[int, int]] = None) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Extract code descriptions from Ontario Schedule of Benefits PDF.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to PDF\n",
        "        page_ranges: List of (start, end) page tuples to scan. If None, scans key sections.\n",
        "\n",
        "    Returns:\n",
        "        Dict mapping code -> description\n",
        "    \"\"\"\n",
        "    if page_ranges is None:\n",
        "        # Default ranges covering main sections\n",
        "        page_ranges = [\n",
        "            (125, 220),   # Consultations and Visits (A-codes)\n",
        "            (300, 400),   # Diagnostic Radiology (X-codes)\n",
        "            (380, 420),   # Diagnostic Ultrasound (J-codes)\n",
        "            (80, 100),    # Special Visit Premiums\n",
        "        ]\n",
        "\n",
        "    code_descriptions = {}\n",
        "\n",
        "    # Pattern to match fee codes with descriptions\n",
        "    # Matches: CODE description....... fee\n",
        "    pattern = re.compile(r'([A-Z]\\d{3})\\s+([A-Za-z][^\\d\\.]{5,80})\\.{2,}')\n",
        "\n",
        "    with pdfplumber.open(filepath) as pdf:\n",
        "        total_pages = len(pdf.pages)\n",
        "\n",
        "        for start, end in page_ranges:\n",
        "            end = min(end, total_pages)\n",
        "\n",
        "            for i in range(start, end):\n",
        "                try:\n",
        "                    text = pdf.pages[i].extract_text()\n",
        "                    if text:\n",
        "                        matches = pattern.findall(text)\n",
        "                        for code, desc in matches:\n",
        "                            desc = desc.strip()\n",
        "                            desc = re.sub(r'\\s+', ' ', desc)  # Normalize whitespace\n",
        "                            if code not in code_descriptions:\n",
        "                                code_descriptions[code] = desc\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "    print(f\"✓ Extracted {len(code_descriptions)} Ontario code descriptions from PDF\")\n",
        "    return code_descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gRALvHw3YKxB"
      },
      "outputs": [],
      "source": [
        "def build_ontario_reference(fee_file: str, pdf_file: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build complete Ontario reference table by joining fee data with PDF descriptions.\n",
        "    \"\"\"\n",
        "    # Load fee data\n",
        "    fees_df = parse_ontario_fee_file(fee_file)\n",
        "\n",
        "    # Extract descriptions from PDF\n",
        "    descriptions = extract_ontario_descriptions_from_pdf(pdf_file)\n",
        "\n",
        "    # Join\n",
        "    fees_df['description'] = fees_df['code'].map(descriptions)\n",
        "    fees_df['province'] = 'ON'\n",
        "\n",
        "    # Infer category from code prefix\n",
        "    def infer_category(code):\n",
        "        prefix = code[0]\n",
        "        category_map = {\n",
        "            'A': 'Consultation/Assessment',\n",
        "            'C': 'Hospital Services',\n",
        "            'K': 'Assessment/Premium',\n",
        "            'J': 'Diagnostic Procedures',\n",
        "            'X': 'Diagnostic Radiology',\n",
        "            'G': 'Diagnostic/Therapeutic',\n",
        "            'Q': 'Premium/Special',\n",
        "            'B': 'Premium/Home Visit',\n",
        "            'W': 'Long-term Care',\n",
        "            'E': 'Add-on/Premium',\n",
        "        }\n",
        "        return category_map.get(prefix, 'Other')\n",
        "\n",
        "    fees_df['category'] = fees_df['code'].apply(infer_category)\n",
        "\n",
        "    # Clean descriptions\n",
        "    fees_df['description_clean'] = fees_df['description'].fillna('').str.lower().str.strip()\n",
        "\n",
        "    # Filter to codes with descriptions for matching\n",
        "    with_desc = fees_df[fees_df['description'].notna()].copy()\n",
        "\n",
        "    print(f\"✓ Built Ontario reference: {len(with_desc)} codes with descriptions\")\n",
        "    return with_desc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqtjqLWRYKxB"
      },
      "source": [
        "## 4. Embedding-Based Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QhHf1_SQYKxB"
      },
      "outputs": [],
      "source": [
        "class SemanticMatcher:\n",
        "    \"\"\"\n",
        "    Semantic matching using sentence embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "        print(f\"Loading embedding model: {model_name}...\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        print(\"✓ Model loaded\")\n",
        "\n",
        "        self.reference_embeddings = None\n",
        "        self.reference_df = None\n",
        "\n",
        "    def index_reference(self, reference_df: pd.DataFrame, text_column: str = 'description_clean'):\n",
        "        \"\"\"\n",
        "        Pre-compute embeddings for reference (Ontario) codes.\n",
        "        \"\"\"\n",
        "        self.reference_df = reference_df.copy()\n",
        "\n",
        "        # Get descriptions\n",
        "        descriptions = reference_df[text_column].fillna('').tolist()\n",
        "\n",
        "        # Compute embeddings\n",
        "        print(f\"Computing embeddings for {len(descriptions)} reference codes...\")\n",
        "        self.reference_embeddings = self.model.encode(descriptions, show_progress_bar=True)\n",
        "        print(\"✓ Reference embeddings computed\")\n",
        "\n",
        "    def find_matches(self,\n",
        "                     query_description: str,\n",
        "                     top_k: int = 5,\n",
        "                     min_similarity: float = 0.3) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Find top-k matching Ontario codes for a given Alberta description.\n",
        "\n",
        "        Returns list of dicts with code, description, similarity, fee.\n",
        "        \"\"\"\n",
        "        if self.reference_embeddings is None:\n",
        "            raise ValueError(\"Must call index_reference() first\")\n",
        "\n",
        "        # Embed query\n",
        "        query_embedding = self.model.encode([query_description.lower()])\n",
        "\n",
        "        # Compute similarities\n",
        "        similarities = cosine_similarity(query_embedding, self.reference_embeddings)[0]\n",
        "\n",
        "        # Get top-k indices\n",
        "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "\n",
        "        matches = []\n",
        "        for idx in top_indices:\n",
        "            sim = similarities[idx]\n",
        "            if sim >= min_similarity:\n",
        "                row = self.reference_df.iloc[idx]\n",
        "                matches.append({\n",
        "                    'on_code': row['code'],\n",
        "                    'on_description': row['description'],\n",
        "                    'on_fee': row['fee'],\n",
        "                    'on_category': row['category'],\n",
        "                    'similarity': float(sim)\n",
        "                })\n",
        "\n",
        "        return matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpU1Un-SYKxB"
      },
      "source": [
        "## 5. Multi-Signal Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Krj9FSLYYKxB"
      },
      "outputs": [],
      "source": [
        "def compute_fee_similarity(ab_fee: float, on_fee: float) -> float:\n",
        "    \"\"\"\n",
        "    Compute fee similarity score (0-1).\n",
        "    Returns 1.0 if fees are identical, decreasing as ratio diverges.\n",
        "    \"\"\"\n",
        "    if ab_fee == 0 or on_fee == 0:\n",
        "        return 0.5  # Neutral if either is zero (premium codes, etc.)\n",
        "\n",
        "    ratio = min(ab_fee, on_fee) / max(ab_fee, on_fee)\n",
        "    return ratio\n",
        "\n",
        "\n",
        "def compute_category_match(ab_category: str, on_category: str) -> float:\n",
        "    \"\"\"\n",
        "    Score category alignment (0-1).\n",
        "    \"\"\"\n",
        "    # Mapping Alberta categories to Ontario\n",
        "    ab_to_on_map = {\n",
        "        'V': ['Consultation/Assessment', 'Hospital Services', 'Premium/Special'],\n",
        "        'T': ['Diagnostic Radiology', 'Diagnostic Procedures', 'Diagnostic/Therapeutic'],\n",
        "    }\n",
        "\n",
        "    expected = ab_to_on_map.get(ab_category, [])\n",
        "\n",
        "    if on_category in expected:\n",
        "        return 1.0\n",
        "    elif any(word in on_category.lower() for word in ['consult', 'assess', 'visit']):\n",
        "        return 0.7\n",
        "    else:\n",
        "        return 0.3\n",
        "\n",
        "\n",
        "def compute_confidence_score(semantic_sim: float,\n",
        "                              fee_sim: float,\n",
        "                              category_match: float,\n",
        "                              weights: Tuple[float, float, float] = (0.6, 0.25, 0.15)) -> float:\n",
        "    \"\"\"\n",
        "    Compute weighted confidence score from multiple signals.\n",
        "\n",
        "    Default weights prioritize semantic similarity.\n",
        "    \"\"\"\n",
        "    w_sem, w_fee, w_cat = weights\n",
        "\n",
        "    score = (w_sem * semantic_sim +\n",
        "             w_fee * fee_sim +\n",
        "             w_cat * category_match)\n",
        "\n",
        "    return round(score, 4)\n",
        "\n",
        "\n",
        "def classify_confidence(score: float) -> str:\n",
        "    \"\"\"\n",
        "    Classify confidence score into High/Medium/Low.\n",
        "    \"\"\"\n",
        "    if score >= 0.75:\n",
        "        return 'High'\n",
        "    elif score >= 0.55:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt0CP3vpYKxB"
      },
      "source": [
        "## 6. Main Crosswalk Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-wJoAxJfYKxC"
      },
      "outputs": [],
      "source": [
        "def run_crosswalk_pipeline(config: Config) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Main pipeline to generate validated crosswalk.\n",
        "\n",
        "    Returns DataFrame with Alberta codes matched to Ontario candidates.\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"BILLING CODE CROSSWALK PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Load data\n",
        "    print(\"\\n[1/4] Loading data...\")\n",
        "    ab_codes = load_alberta_codes(config.alberta_file)\n",
        "    on_reference = build_ontario_reference(config.ontario_fee_file, config.ontario_pdf_file)\n",
        "\n",
        "    # 2. Initialize matcher\n",
        "    print(\"\\n[2/4] Initializing semantic matcher...\")\n",
        "    matcher = SemanticMatcher(config.embedding_model)\n",
        "    matcher.index_reference(on_reference)\n",
        "\n",
        "    # 3. Find matches for each Alberta code\n",
        "    print(\"\\n[3/4] Finding matches...\")\n",
        "    results = []\n",
        "\n",
        "    for _, ab_row in ab_codes.iterrows():\n",
        "        ab_code = ab_row['code']\n",
        "        ab_desc = ab_row['description']\n",
        "        ab_fee = ab_row['fee']\n",
        "        ab_cat = ab_row['category']\n",
        "\n",
        "        # Get candidate matches\n",
        "        matches = matcher.find_matches(\n",
        "            ab_desc,\n",
        "            top_k=config.top_k_matches,\n",
        "            min_similarity=config.min_similarity_threshold\n",
        "        )\n",
        "\n",
        "        for rank, match in enumerate(matches, 1):\n",
        "            # Compute validation signals\n",
        "            fee_sim = compute_fee_similarity(ab_fee, match['on_fee'])\n",
        "            cat_match = compute_category_match(ab_cat, match['on_category'])\n",
        "            confidence = compute_confidence_score(\n",
        "                match['similarity'], fee_sim, cat_match\n",
        "            )\n",
        "\n",
        "            results.append({\n",
        "                'ab_code': ab_code,\n",
        "                'ab_description': ab_desc,\n",
        "                'ab_fee': ab_fee,\n",
        "                'ab_category': ab_cat,\n",
        "                'match_rank': rank,\n",
        "                'on_code': match['on_code'],\n",
        "                'on_description': match['on_description'],\n",
        "                'on_fee': match['on_fee'],\n",
        "                'on_category': match['on_category'],\n",
        "                'semantic_similarity': round(match['similarity'], 4),\n",
        "                'fee_similarity': round(fee_sim, 4),\n",
        "                'category_match': round(cat_match, 4),\n",
        "                'confidence_score': confidence,\n",
        "                'confidence_level': classify_confidence(confidence),\n",
        "                'fee_ratio': round(match['on_fee'] / ab_fee, 2) if ab_fee > 0 else None,\n",
        "            })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # 4. Add QA flags\n",
        "    print(\"\\n[4/4] Adding QA flags...\")\n",
        "\n",
        "    def add_qa_flags(row):\n",
        "        flags = []\n",
        "\n",
        "        # Fee discrepancy flag\n",
        "        if row['fee_ratio'] and (row['fee_ratio'] < 0.5 or row['fee_ratio'] > 2.0):\n",
        "            flags.append(f\"FEE_DISCREPANCY ({row['fee_ratio']}x)\")\n",
        "\n",
        "        # Low semantic similarity\n",
        "        if row['semantic_similarity'] < 0.5:\n",
        "            flags.append(\"LOW_SEMANTIC_MATCH\")\n",
        "\n",
        "        # Category mismatch\n",
        "        if row['category_match'] < 0.5:\n",
        "            flags.append(\"CATEGORY_MISMATCH\")\n",
        "\n",
        "        return '; '.join(flags) if flags else '✓'\n",
        "\n",
        "    results_df['qa_flags'] = results_df.apply(add_qa_flags, axis=1)\n",
        "\n",
        "    print(f\"\\n✓ Pipeline complete: {len(results_df)} match candidates generated\")\n",
        "    print(f\"  - High confidence: {len(results_df[results_df['confidence_level']=='High'])}\")\n",
        "    print(f\"  - Medium confidence: {len(results_df[results_df['confidence_level']=='Medium'])}\")\n",
        "    print(f\"  - Low confidence: {len(results_df[results_df['confidence_level']=='Low'])}\")\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7XtIN1vYKxC"
      },
      "source": [
        "## 7. Export Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "48c6-F1sYKxC"
      },
      "outputs": [],
      "source": [
        "def export_crosswalk(results_df: pd.DataFrame, output_file: str):\n",
        "    \"\"\"\n",
        "    Export results to formatted Excel file.\n",
        "    \"\"\"\n",
        "    from openpyxl import Workbook\n",
        "    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
        "    from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "    # Create workbook with multiple sheets\n",
        "    wb = Workbook()\n",
        "\n",
        "    # Sheet 1: Best matches only (rank 1)\n",
        "    ws1 = wb.active\n",
        "    ws1.title = \"Best Matches\"\n",
        "\n",
        "    best_matches = results_df[results_df['match_rank'] == 1].copy()\n",
        "\n",
        "    # Headers\n",
        "    headers = ['AB Code', 'AB Description', 'AB Fee', 'ON Code', 'ON Description',\n",
        "               'ON Fee', 'Semantic Sim', 'Fee Ratio', 'Confidence', 'QA Flags']\n",
        "\n",
        "    for col, header in enumerate(headers, 1):\n",
        "        cell = ws1.cell(row=1, column=col, value=header)\n",
        "        cell.font = Font(bold=True)\n",
        "        cell.fill = PatternFill(start_color=\"0B1F33\", fill_type=\"solid\")\n",
        "        cell.font = Font(bold=True, color=\"FFFFFF\")\n",
        "\n",
        "    # Data\n",
        "    for row_idx, row in enumerate(best_matches.itertuples(), 2):\n",
        "        ws1.cell(row=row_idx, column=1, value=row.ab_code)\n",
        "        ws1.cell(row=row_idx, column=2, value=row.ab_description)\n",
        "        ws1.cell(row=row_idx, column=3, value=row.ab_fee)\n",
        "        ws1.cell(row=row_idx, column=4, value=row.on_code)\n",
        "        ws1.cell(row=row_idx, column=5, value=row.on_description)\n",
        "        ws1.cell(row=row_idx, column=6, value=row.on_fee)\n",
        "        ws1.cell(row=row_idx, column=7, value=row.semantic_similarity)\n",
        "        ws1.cell(row=row_idx, column=8, value=row.fee_ratio)\n",
        "        ws1.cell(row=row_idx, column=9, value=row.confidence_level)\n",
        "        ws1.cell(row=row_idx, column=10, value=row.qa_flags)\n",
        "\n",
        "        # Color code confidence\n",
        "        conf_cell = ws1.cell(row=row_idx, column=9)\n",
        "        if row.confidence_level == 'High':\n",
        "            conf_cell.font = Font(color=\"0FB9B1\", bold=True)\n",
        "        elif row.confidence_level == 'Medium':\n",
        "            conf_cell.font = Font(color=\"D97706\", bold=True)\n",
        "        else:\n",
        "            conf_cell.font = Font(color=\"DC2626\", bold=True)\n",
        "\n",
        "    # Sheet 2: All candidates\n",
        "    ws2 = wb.create_sheet(\"All Candidates\")\n",
        "    for r_idx, row in enumerate(dataframe_to_rows(results_df, index=False, header=True), 1):\n",
        "        for c_idx, value in enumerate(row, 1):\n",
        "            ws2.cell(row=r_idx, column=c_idx, value=value)\n",
        "\n",
        "    # Sheet 3: Summary stats\n",
        "    ws3 = wb.create_sheet(\"Summary\")\n",
        "    ws3['A1'] = \"Crosswalk Summary Statistics\"\n",
        "    ws3['A1'].font = Font(bold=True, size=14)\n",
        "\n",
        "    stats = [\n",
        "        (\"\", \"\"),\n",
        "        (\"Total Alberta Codes\", len(best_matches)),\n",
        "        (\"High Confidence Matches\", len(best_matches[best_matches['confidence_level']=='High'])),\n",
        "        (\"Medium Confidence Matches\", len(best_matches[best_matches['confidence_level']=='Medium'])),\n",
        "        (\"Low Confidence Matches\", len(best_matches[best_matches['confidence_level']=='Low'])),\n",
        "        (\"\", \"\"),\n",
        "        (\"Average Semantic Similarity\", round(best_matches['semantic_similarity'].mean(), 3)),\n",
        "        (\"Average Fee Ratio (ON/AB)\", round(best_matches['fee_ratio'].mean(), 3)),\n",
        "        (\"\", \"\"),\n",
        "        (\"Codes with QA Flags\", len(best_matches[best_matches['qa_flags'] != '✓'])),\n",
        "    ]\n",
        "\n",
        "    for row_idx, (label, value) in enumerate(stats, 3):\n",
        "        ws3.cell(row=row_idx, column=1, value=label)\n",
        "        ws3.cell(row=row_idx, column=2, value=value)\n",
        "\n",
        "    # Save\n",
        "    wb.save(output_file)\n",
        "    print(f\"\\n✓ Exported to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xiS6qLsYKxC"
      },
      "source": [
        "## 8. Run the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "31nC7vF0YKxC"
      },
      "outputs": [],
      "source": [
        "# Upload your files to Colab first, then run:\n",
        "\n",
        "# Option 1: Upload files manually via Colab UI\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Option 2: Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# config.alberta_file = '/content/drive/MyDrive/path/to/merged_output_AB__2_.xlsx'\n",
        "# config.ontario_fee_file = '/content/drive/MyDrive/path/to/OCTSOB2025.001 2'\n",
        "# config.ontario_pdf_file = '/content/drive/MyDrive/path/to/moh-schedule-benefit-2024-03-04.pdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "zxuXS8jtYKxC",
        "outputId": "288204db-8a74-41a8-d6f8-43d1af42abb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "BILLING CODE CROSSWALK PIPELINE\n",
            "============================================================\n",
            "\n",
            "[1/4] Loading data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'merged_output_AB__2_.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1290486982.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_crosswalk_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1284634388.py\u001b[0m in \u001b[0;36mrun_crosswalk_pipeline\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 1. Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[1/4] Loading data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mab_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_alberta_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malberta_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mon_reference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_ontario_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0montario_fee_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0montario_pdf_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3559570748.py\u001b[0m in \u001b[0;36mload_alberta_codes\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mdeduplicated\u001b[0m \u001b[0mcodes\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdescriptions\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Get unique codes with their core attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'merged_output_AB__2_.xlsx'"
          ]
        }
      ],
      "source": [
        "# Run the pipeline\n",
        "results = run_crosswalk_pipeline(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTeXJdLhYKxC"
      },
      "outputs": [],
      "source": [
        "# View best matches\n",
        "best_matches = results[results['match_rank'] == 1]\n",
        "display(best_matches[['ab_code', 'ab_description', 'ab_fee', 'on_code', 'on_description',\n",
        "                       'on_fee', 'semantic_similarity', 'confidence_level', 'qa_flags']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHmQ7KXDYKxD"
      },
      "outputs": [],
      "source": [
        "# Export results\n",
        "export_crosswalk(results, config.output_file)\n",
        "\n",
        "# Download file (Colab)\n",
        "# from google.colab import files\n",
        "# files.download(config.output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKlDZuPYKxD"
      },
      "source": [
        "## 9. Manual Review Helper\n",
        "\n",
        "Use this to inspect specific codes that need attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuXNPDx5YKxD"
      },
      "outputs": [],
      "source": [
        "def review_code(ab_code: str, results_df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Display all candidate matches for a specific Alberta code.\n",
        "    \"\"\"\n",
        "    matches = results_df[results_df['ab_code'] == ab_code].copy()\n",
        "\n",
        "    if len(matches) == 0:\n",
        "        print(f\"No matches found for {ab_code}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ALBERTA CODE: {ab_code}\")\n",
        "    print(f\"Description: {matches.iloc[0]['ab_description']}\")\n",
        "    print(f\"Fee: ${matches.iloc[0]['ab_fee']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(f\"\\nTop {len(matches)} Ontario Candidates:\\n\")\n",
        "\n",
        "    for _, row in matches.iterrows():\n",
        "        print(f\"  [{row['match_rank']}] {row['on_code']}: {row['on_description']}\")\n",
        "        print(f\"      Fee: ${row['on_fee']:.2f} | Ratio: {row['fee_ratio']}x\")\n",
        "        print(f\"      Semantic: {row['semantic_similarity']:.3f} | Confidence: {row['confidence_level']}\")\n",
        "        print(f\"      Flags: {row['qa_flags']}\")\n",
        "        print()\n",
        "\n",
        "# Example usage:\n",
        "# review_code('03.03A', results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH9Rjde4YKxD"
      },
      "outputs": [],
      "source": [
        "def get_flagged_codes(results_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Return all codes that have QA flags for manual review.\n",
        "    \"\"\"\n",
        "    best = results_df[results_df['match_rank'] == 1]\n",
        "    flagged = best[best['qa_flags'] != '✓']\n",
        "\n",
        "    print(f\"Codes requiring review: {len(flagged)}\")\n",
        "    return flagged[['ab_code', 'ab_description', 'on_code', 'on_description',\n",
        "                    'confidence_level', 'qa_flags']]\n",
        "\n",
        "# Example usage:\n",
        "# flagged = get_flagged_codes(results)\n",
        "# display(flagged)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxfwKcJvYKxD"
      },
      "source": [
        "## 10. Validation Against Known Mappings\n",
        "\n",
        "If you have expert-validated mappings, use this to measure accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txfKycBtYKxD"
      },
      "outputs": [],
      "source": [
        "def validate_against_ground_truth(results_df: pd.DataFrame,\n",
        "                                   ground_truth: Dict[str, str]) -> Dict:\n",
        "    \"\"\"\n",
        "    Validate pipeline results against known correct mappings.\n",
        "\n",
        "    Args:\n",
        "        results_df: Pipeline output\n",
        "        ground_truth: Dict mapping ab_code -> correct_on_code\n",
        "\n",
        "    Returns:\n",
        "        Dict with accuracy metrics\n",
        "    \"\"\"\n",
        "    best_matches = results_df[results_df['match_rank'] == 1].copy()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    errors = []\n",
        "\n",
        "    for ab_code, correct_on in ground_truth.items():\n",
        "        match = best_matches[best_matches['ab_code'] == ab_code]\n",
        "\n",
        "        if len(match) == 0:\n",
        "            errors.append((ab_code, 'NO_MATCH', correct_on))\n",
        "            total += 1\n",
        "            continue\n",
        "\n",
        "        predicted_on = match.iloc[0]['on_code']\n",
        "\n",
        "        # Check if correct (allowing for composite codes)\n",
        "        if correct_on in predicted_on or predicted_on in correct_on:\n",
        "            correct += 1\n",
        "        else:\n",
        "            errors.append((ab_code, predicted_on, correct_on))\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'correct': correct,\n",
        "        'total': total,\n",
        "        'errors': errors\n",
        "    }\n",
        "\n",
        "# Example: Define known correct mappings for validation\n",
        "# ground_truth = {\n",
        "#     '03.03A': 'A001',\n",
        "#     '03.04A': 'A007',\n",
        "#     '03.08A': 'A005',\n",
        "#     'X310': 'J135',\n",
        "# }\n",
        "#\n",
        "# validation = validate_against_ground_truth(results, ground_truth)\n",
        "# print(f\"Accuracy: {validation['accuracy']:.1%}\")\n",
        "# print(f\"Errors: {validation['errors']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxwbwFPJYKxD"
      },
      "source": [
        "---\n",
        "\n",
        "## Notes for Production Use\n",
        "\n",
        "1. **Embedding Model**: Consider using a medical-domain model like `pritamdeka/S-PubMedBert-MS-MARCO` for better clinical terminology matching.\n",
        "\n",
        "2. **Fee Data**: The Ontario fee file format may change between releases. Verify the field positions.\n",
        "\n",
        "3. **PDF Extraction**: The regex patterns may need adjustment for different SOB PDF versions.\n",
        "\n",
        "4. **Confidence Thresholds**: Tune based on your tolerance for false positives vs. false negatives.\n",
        "\n",
        "5. **Human Review**: Always have a domain expert review Low and Medium confidence matches.\n",
        "\n",
        "6. **Version Control**: Track which versions of the AB and ON fee schedules were used."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}