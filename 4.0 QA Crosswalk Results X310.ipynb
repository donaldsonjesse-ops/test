{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 QA Crosswalk Results - X310 Abdominal Ultrasound\n",
    "\n",
    "Quality assurance for abdominal ultrasound billing code crosswalk outputs.\n",
    "\n",
    "**Workflow**\n",
    "1. Upload crosswalk results\n",
    "2. Clean and standardize data\n",
    "3. Run QA classification (HIGH/MEDIUM/LOW)\n",
    "4. Export branded results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pandas openpyxl tqdm xlsxwriter -q\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from google.colab import files\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# ============================================================================\n",
    "# HELPSEEKER BRAND COLOURS\n",
    "# ============================================================================\n",
    "BRAND = {\n",
    "    'deep_navy': '#0B1F33',\n",
    "    'midnight_blue': '#102A43',\n",
    "    'teal_core': '#0FB9B1',\n",
    "    'aqua_light': '#4FD1C5',\n",
    "    'slate_blue': '#1E3A5F',\n",
    "    'white': '#FFFFFF',\n",
    "    'near_black': '#0A0A0A',\n",
    "}\n",
    "\n",
    "# QA Confidence colours\n",
    "QA_COLORS = {\n",
    "    'HIGH': BRAND['teal_core'],\n",
    "    'MEDIUM': BRAND['aqua_light'],\n",
    "    'LOW': BRAND['slate_blue'],\n",
    "}\n",
    "\n",
    "print(\"Dependencies loaded.\")\n",
    "print(\"HelpSeeker brand palette configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Alberta Code Reference\n",
    "\n",
    "Source code definition for QA comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ALBERTA CODE REFERENCE (X310)\n",
    "# ============================================================================\n",
    "# This defines the source code for QA comparison.\n",
    "# Update this if QA'ing a different Alberta code.\n",
    "# ============================================================================\n",
    "\n",
    "ALBERTA_CODE_REF = {\n",
    "    'code': 'X310',\n",
    "    'description': 'Ultrasound, abdominal, complete or at least two abdominal organs',\n",
    "    'fee': 171.68,\n",
    "    'category': 'T Test (Diagnostic)',\n",
    "    \n",
    "    'clinical_definition': \"\"\"Complete abdominal ultrasound examination OR ultrasound of at least two abdominal organs.\n",
    "\n",
    "DIAGNOSTIC ULTRASOUND RULES:\n",
    "- Includes Doppler colour mapping\n",
    "- Quantitative spectral analysis with directional flow and/or Doppler measurements (HSC X337) may be claimed IN ADDITION to this code\n",
    "- May NOT be claimed same day as X311 (limited abdominal) or X312 by same or different physician in same location\n",
    "\n",
    "DIAGNOSTIC RADIOLOGY RULES:\n",
    "- Physician must be CPSA-approved to provide diagnostic radiology services (G.R. 11.1.1)\n",
    "\n",
    "FEE MODIFIERS:\n",
    "- AGE modifier L13: 30% increase for patients 12 years and younger (base increases to 130% = $223.18)\n",
    "\n",
    "SAME-DAY EXCLUSIONS:\n",
    "- X311 (limited abdominal ultrasound)\n",
    "- X312\n",
    "- Cannot be claimed by same or different physician in same location on same day\n",
    "\n",
    "SCOPE OF EXAMINATION:\n",
    "- Complete abdominal scan typically includes: liver, gallbladder, bile ducts, pancreas, spleen, kidneys, aorta, IVC\n",
    "- OR at minimum two abdominal organs\"\"\",\n",
    "    \n",
    "    'service_type': 'Diagnostic imaging procedure (ultrasound)',\n",
    "    \n",
    "    'key_attributes': [\n",
    "        'Diagnostic imaging procedure (NOT a visit/consultation)',\n",
    "        'Abdominal ultrasound (complete or multi-organ)',\n",
    "        'Includes Doppler colour mapping',\n",
    "        'Pediatric age premium (12 years and younger)',\n",
    "        'Requires CPSA approval for diagnostic radiology',\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ALBERTA CODE REFERENCE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nCode: {ALBERTA_CODE_REF['code']}\")\n",
    "print(f\"Description: {ALBERTA_CODE_REF['description']}\")\n",
    "print(f\"Fee: ${ALBERTA_CODE_REF['fee']}\")\n",
    "print(f\"Category: {ALBERTA_CODE_REF['category']}\")\n",
    "print(f\"\\nKey Attributes:\")\n",
    "for attr in ALBERTA_CODE_REF['key_attributes']:\n",
    "    print(f\"  â€¢ {attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Upload Crosswalk File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"UPLOAD CROSSWALK RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nUpload your crosswalk Excel file\")\n",
    "print()\n",
    "\n",
    "uploaded = files.upload()\n",
    "INPUT_FILE = list(uploaded.keys())[0]\n",
    "\n",
    "df = pd.read_excel(INPUT_FILE)\n",
    "\n",
    "print(f\"\\nLoaded: {INPUT_FILE}\")\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CLEANING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove numbering prefixes, standardize capitalization.\"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # Remove leading numbering: \"7.\", \"8.\", \"9.\", \"10.\", \"11a.\" etc.\n",
    "    text = re.sub(r'^\\d+[a-z]?\\.\\s*', '', text.strip())\n",
    "    \n",
    "    # Sentence case (capitalize first letter)\n",
    "    if text:\n",
    "        text = text[0].upper() + text[1:] if len(text) > 1 else text.upper()\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def clean_section(text):\n",
    "    \"\"\"Clean section names.\"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return text\n",
    "    # Remove leading numbering\n",
    "    text = re.sub(r'^\\d+[a-z]?\\.\\s*', '', text.strip())\n",
    "    return text.strip()\n",
    "\n",
    "# Clean columns\n",
    "text_cols = ['Description', 'AB_Description', 'Reasoning', 'additional_notes']\n",
    "section_cols = ['Level_1_Section', 'Level_2_Subsection', 'Level_3_Heading', 'Specialty']\n",
    "\n",
    "for col in text_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "        print(f\"  Cleaned: {col}\")\n",
    "\n",
    "for col in section_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_section)\n",
    "        print(f\"  Cleaned: {col}\")\n",
    "\n",
    "# Standardize case\n",
    "if 'Type' in df.columns:\n",
    "    df['Type'] = df['Type'].str.upper()\n",
    "if 'Modality' in df.columns:\n",
    "    df['Modality'] = df['Modality'].str.lower()\n",
    "if 'Target_Province' in df.columns:\n",
    "    df['Target_Province'] = df['Target_Province'].str.upper()\n",
    "\n",
    "print(f\"\\nCleaning complete. Rows: {len(df)}\")\n",
    "\n",
    "# Save cleaned file\n",
    "cleaned_file = INPUT_FILE.replace('.xlsx', '_CLEANED.xlsx')\n",
    "df.to_excel(cleaned_file, index=False)\n",
    "print(f\"Saved: {cleaned_file}\")\n",
    "files.download(cleaned_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"  # Paste key here or leave blank for prompt\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    from getpass import getpass\n",
    "    OPENAI_API_KEY = getpass(\"Enter OpenAI API Key: \")\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(\"API client initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: QA Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"QA CLASSIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "total_cost = 0.0\n",
    "total_calls = 0\n",
    "\n",
    "def track_cost(inp, out):\n",
    "    global total_cost, total_calls\n",
    "    total_cost += (inp/1e6)*3.0 + (out/1e6)*15.0\n",
    "    total_calls += 1\n",
    "\n",
    "def build_qa_prompt(rows_batch):\n",
    "    \"\"\"Build abdominal ultrasound-specific QA prompt.\"\"\"\n",
    "    \n",
    "    rows_text = \"\"\n",
    "    for idx, row in rows_batch.iterrows():\n",
    "        rows_text += f\"\"\"\n",
    "ROW {idx}:\n",
    "  Province: {row.get('Target_Province', 'N/A')}\n",
    "  Code: {row.get('Code', 'N/A')}\n",
    "  Description: {row.get('Description', 'N/A')}\n",
    "  Fee: {row.get('Fee', 'N/A')}\n",
    "  Type: {row.get('Type', 'N/A')}\n",
    "  Modality: {row.get('Modality', 'N/A')}\n",
    "  Reasoning: {row.get('Reasoning', 'N/A')}\n",
    "\"\"\"\n",
    "    \n",
    "    return f\"\"\"You are a senior physician billing specialist performing quality assurance on a diagnostic imaging billing code crosswalk.\n",
    "\n",
    "ALBERTA SOURCE CODE: {ALBERTA_CODE_REF['code']}\n",
    "Description: {ALBERTA_CODE_REF['description']}\n",
    "Fee: ${ALBERTA_CODE_REF['fee']}\n",
    "\n",
    "CLINICAL DEFINITION:\n",
    "{ALBERTA_CODE_REF['clinical_definition']}\n",
    "\n",
    "KEY MATCHING CRITERIA:\n",
    "1. Must be ABDOMINAL ULTRASOUND (not other body regions)\n",
    "2. Must be COMPLETE or MULTI-ORGAN examination (at least 2 abdominal organs)\n",
    "3. Should be DIAGNOSTIC imaging (not interventional/guided procedures)\n",
    "4. Doppler/colour flow inclusion is a bonus match indicator\n",
    "5. Pediatric age modifiers should be noted if present\n",
    "\n",
    "TARGET CODES TO EVALUATE:\n",
    "{rows_text}\n",
    "\n",
    "CLASSIFICATION CRITERIA:\n",
    "\n",
    "**HIGH** - Strong crosswalk match:\n",
    "- Complete abdominal ultrasound or multi-organ abdominal scan\n",
    "- Covers similar anatomical scope (liver, gallbladder, pancreas, spleen, kidneys, etc.)\n",
    "- Diagnostic ultrasound (not procedure/guidance)\n",
    "- Similar clinical scope to X310\n",
    "- Includes or compatible with Doppler imaging\n",
    "\n",
    "**MEDIUM** - Partial match with caveats:\n",
    "- Abdominal ultrasound but limited scope (fewer organs than complete)\n",
    "- Regional abdominal ultrasound (e.g., upper abdomen only, RUQ only)\n",
    "- Similar service but significantly different fee structure\n",
    "- Add-on code that supplements a primary abdominal ultrasound match\n",
    "- Doppler-specific codes that may apply to abdominal imaging\n",
    "\n",
    "**LOW** - Weak or incorrect match:\n",
    "- Single organ ultrasound only (e.g., gallbladder only, kidney only)\n",
    "- Non-abdominal ultrasound (pelvic, obstetric, cardiac, vascular, MSK)\n",
    "- Ultrasound-guided procedures (biopsy, drainage, injection)\n",
    "- CT or MRI codes (wrong imaging modality)\n",
    "- X-ray or fluoroscopy codes\n",
    "- Unrelated diagnostic service\n",
    "\n",
    "Return JSON array:\n",
    "[\n",
    "  {{\n",
    "    \"row_index\": <integer>,\n",
    "    \"qa_confidence\": \"HIGH|MEDIUM|LOW\",\n",
    "    \"target_code\": \"the code being evaluated\",\n",
    "    \"qa_rationale\": \"1-2 sentence explanation\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "JSON only:\"\"\"\n",
    "\n",
    "def run_qa_batch(rows_batch):\n",
    "    \"\"\"Run QA on batch of 5 rows.\"\"\"\n",
    "    prompt = build_qa_prompt(rows_batch)\n",
    "    \n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-2025-04-14\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            max_completion_tokens=2000\n",
    "        )\n",
    "        track_cost(resp.usage.prompt_tokens, resp.usage.completion_tokens)\n",
    "        \n",
    "        content = resp.choices[0].message.content\n",
    "        match = re.search(r'\\[.*\\]', content, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group())\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {e}\")\n",
    "        return []\n",
    "\n",
    "# Initialize QA columns\n",
    "df['QA_Confidence'] = ''\n",
    "df['QA_Rationale'] = ''\n",
    "\n",
    "print(f\"\\nRows to QA: {len(df)}\")\n",
    "print(f\"Batch size: 5 rows per API call\")\n",
    "print(f\"Estimated API calls: {(len(df) + 4) // 5}\")\n",
    "\n",
    "# Process in batches of 5\n",
    "batch_size = 5\n",
    "total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "\n",
    "for batch_num in tqdm(range(total_batches), desc=\"QA Progress\"):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(df))\n",
    "    \n",
    "    batch_df = df.iloc[start_idx:end_idx]\n",
    "    results = run_qa_batch(batch_df)\n",
    "    \n",
    "    for result in results:\n",
    "        row_idx = result.get('row_index')\n",
    "        if row_idx is not None and 0 <= row_idx < len(df):\n",
    "            df.at[row_idx, 'QA_Confidence'] = result.get('qa_confidence', '')\n",
    "            df.at[row_idx, 'QA_Rationale'] = result.get('qa_rationale', '')\n",
    "\n",
    "print(f\"\\nQA Complete\")\n",
    "print(f\"API calls: {total_calls}\")\n",
    "print(f\"Cost: ${total_cost:.2f}\")\n",
    "\n",
    "print(f\"\\n--- QA Summary ---\")\n",
    "print(df['QA_Confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Export Branded Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXPORT BRANDED RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# COLUMN ORDERING\n",
    "# ============================================================================\n",
    "# 1. Alberta source columns first\n",
    "# 2. Target province key info\n",
    "# 3. QA results\n",
    "# 4. Other columns (Setting, Premiums, Fee_Type before additional_notes)\n",
    "# 5. additional_notes LAST\n",
    "# ============================================================================\n",
    "\n",
    "ab_cols = ['AB_Code', 'AB_Description', 'AB_Fee']\n",
    "key_cols = ['Target_Province', 'Code', 'Description', 'Fee', 'Type', 'Modality']\n",
    "qa_cols = ['QA_Confidence', 'QA_Rationale']\n",
    "late_cols = ['Setting', 'Fee_Type', 'premium_extended_hours', 'premium_location', 'premium_age', 'premium_other']\n",
    "last_col = ['additional_notes']\n",
    "\n",
    "# Build column order\n",
    "col_order = []\n",
    "col_order += [c for c in ab_cols if c in df.columns]\n",
    "col_order += [c for c in key_cols if c in df.columns]\n",
    "col_order += [c for c in qa_cols if c in df.columns]\n",
    "\n",
    "# Add remaining columns except late_cols and last_col\n",
    "used_cols = set(col_order + late_cols + last_col)\n",
    "other_cols = [c for c in df.columns if c not in used_cols]\n",
    "col_order += other_cols\n",
    "\n",
    "# Add late columns (Setting, Fee_Type, Premiums)\n",
    "col_order += [c for c in late_cols if c in df.columns]\n",
    "\n",
    "# Add additional_notes last\n",
    "col_order += [c for c in last_col if c in df.columns]\n",
    "\n",
    "df_final = df[col_order].copy()\n",
    "\n",
    "# Sort by province, then confidence\n",
    "conf_order = {'HIGH': 0, 'MEDIUM': 1, 'LOW': 2, '': 3}\n",
    "df_final['_sort'] = df_final['QA_Confidence'].map(conf_order)\n",
    "df_final = df_final.sort_values(['Target_Province', '_sort', 'Code']).drop(columns=['_sort'])\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "# Save with brand formatting\n",
    "final_file = INPUT_FILE.replace('.xlsx', '_QA_FINAL.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(final_file, engine='xlsxwriter') as writer:\n",
    "    df_final.to_excel(writer, sheet_name='QA Results', index=False)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['QA Results']\n",
    "    \n",
    "    # HelpSeeker brand formats\n",
    "    header_fmt = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'font_name': 'Lato',\n",
    "        'font_size': 11,\n",
    "        'bg_color': BRAND['deep_navy'],\n",
    "        'font_color': BRAND['white'],\n",
    "        'border': 1,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter',\n",
    "    })\n",
    "    \n",
    "    high_fmt = workbook.add_format({\n",
    "        'font_name': 'Lato',\n",
    "        'bg_color': '#D4F5F3',  # Light teal\n",
    "        'font_color': BRAND['near_black'],\n",
    "    })\n",
    "    \n",
    "    medium_fmt = workbook.add_format({\n",
    "        'font_name': 'Lato',\n",
    "        'bg_color': '#E8F8F7',  # Lighter aqua\n",
    "        'font_color': BRAND['near_black'],\n",
    "    })\n",
    "    \n",
    "    low_fmt = workbook.add_format({\n",
    "        'font_name': 'Lato',\n",
    "        'bg_color': '#F0F4F8',  # Light slate\n",
    "        'font_color': BRAND['slate_blue'],\n",
    "    })\n",
    "    \n",
    "    # Apply header format\n",
    "    for col_num, value in enumerate(df_final.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_fmt)\n",
    "    \n",
    "    # Set column widths\n",
    "    col_widths = {\n",
    "        'AB_Code': 10,\n",
    "        'AB_Description': 25,\n",
    "        'AB_Fee': 10,\n",
    "        'Target_Province': 12,\n",
    "        'Code': 12,\n",
    "        'Description': 50,\n",
    "        'Fee': 10,\n",
    "        'Type': 10,\n",
    "        'Modality': 12,\n",
    "        'QA_Confidence': 14,\n",
    "        'QA_Rationale': 60,\n",
    "        'Setting': 12,\n",
    "        'Fee_Type': 12,\n",
    "        'additional_notes': 50,\n",
    "    }\n",
    "    \n",
    "    for col_idx, col_name in enumerate(df_final.columns):\n",
    "        width = col_widths.get(col_name, 15)\n",
    "        worksheet.set_column(col_idx, col_idx, width)\n",
    "    \n",
    "    # Conditional formatting for QA_Confidence column\n",
    "    if 'QA_Confidence' in df_final.columns:\n",
    "        qa_col_idx = list(df_final.columns).index('QA_Confidence')\n",
    "        col_letter = chr(65 + qa_col_idx) if qa_col_idx < 26 else 'A'  # Handle >26 cols\n",
    "        \n",
    "        worksheet.conditional_format(f'{col_letter}2:{col_letter}{len(df_final)+1}', {\n",
    "            'type': 'text',\n",
    "            'criteria': 'containing',\n",
    "            'value': 'HIGH',\n",
    "            'format': high_fmt\n",
    "        })\n",
    "        worksheet.conditional_format(f'{col_letter}2:{col_letter}{len(df_final)+1}', {\n",
    "            'type': 'text',\n",
    "            'criteria': 'containing',\n",
    "            'value': 'MEDIUM',\n",
    "            'format': medium_fmt\n",
    "        })\n",
    "        worksheet.conditional_format(f'{col_letter}2:{col_letter}{len(df_final)+1}', {\n",
    "            'type': 'text',\n",
    "            'criteria': 'containing',\n",
    "            'value': 'LOW',\n",
    "            'format': low_fmt\n",
    "        })\n",
    "    \n",
    "    # Freeze header row\n",
    "    worksheet.freeze_panes(1, 0)\n",
    "\n",
    "print(f\"\\nSaved: {final_file}\")\n",
    "print(f\"Rows: {len(df_final)}\")\n",
    "\n",
    "# Show column order\n",
    "print(f\"\\n--- Column Order ---\")\n",
    "for i, col in enumerate(df_final.columns[:15], 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "if len(df_final.columns) > 15:\n",
    "    print(f\"  ... and {len(df_final.columns) - 15} more\")\n",
    "\n",
    "# Summary stats\n",
    "print(f\"\\n--- By Confidence ---\")\n",
    "for conf in ['HIGH', 'MEDIUM', 'LOW']:\n",
    "    count = len(df_final[df_final['QA_Confidence'] == conf])\n",
    "    pct = count / len(df_final) * 100 if len(df_final) > 0 else 0\n",
    "    print(f\"  {conf}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n--- By Province ---\")\n",
    "for prov in sorted(df_final['Target_Province'].unique()):\n",
    "    prov_df = df_final[df_final['Target_Province'] == prov]\n",
    "    h = len(prov_df[prov_df['QA_Confidence'] == 'HIGH'])\n",
    "    m = len(prov_df[prov_df['QA_Confidence'] == 'MEDIUM'])\n",
    "    l = len(prov_df[prov_df['QA_Confidence'] == 'LOW'])\n",
    "    print(f\"  {prov}: {len(prov_df)} total (H:{h} M:{m} L:{l})\")\n",
    "\n",
    "files.download(final_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Display Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display branded HTML table\n",
    "def style_qa_table(df_display):\n",
    "    \"\"\"Apply HelpSeeker brand styling to table.\"\"\"\n",
    "    \n",
    "    def highlight_confidence(val):\n",
    "        if val == 'HIGH':\n",
    "            return f'background-color: #D4F5F3; color: {BRAND[\"near_black\"]}; font-weight: bold;'\n",
    "        elif val == 'MEDIUM':\n",
    "            return f'background-color: #E8F8F7; color: {BRAND[\"near_black\"]};'\n",
    "        elif val == 'LOW':\n",
    "            return f'background-color: #F0F4F8; color: {BRAND[\"slate_blue\"]};'\n",
    "        return ''\n",
    "    \n",
    "    styled = df_display.style\\\n",
    "        .applymap(highlight_confidence, subset=['QA_Confidence'])\\\n",
    "        .set_properties(**{\n",
    "            'font-family': 'Lato, sans-serif',\n",
    "            'font-size': '12px',\n",
    "            'text-align': 'left',\n",
    "            'padding': '8px',\n",
    "        })\\\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', 'props': [\n",
    "                ('background-color', BRAND['deep_navy']),\n",
    "                ('color', BRAND['white']),\n",
    "                ('font-family', 'Lato, sans-serif'),\n",
    "                ('font-weight', 'bold'),\n",
    "                ('font-size', '12px'),\n",
    "                ('padding', '10px'),\n",
    "                ('text-align', 'left'),\n",
    "            ]},\n",
    "            {'selector': 'td', 'props': [\n",
    "                ('border-bottom', f'1px solid {BRAND[\"slate_blue\"]}20'),\n",
    "            ]},\n",
    "        ])\n",
    "    \n",
    "    return styled\n",
    "\n",
    "# Select display columns\n",
    "display_cols = ['Target_Province', 'Code', 'Description', 'Fee', 'Modality', 'QA_Confidence', 'QA_Rationale']\n",
    "display_cols = [c for c in display_cols if c in df_final.columns]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL QA RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Display styled table\n",
    "style_qa_table(df_final[display_cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
